{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = \"data/smart_irrigation_chunk_wheat.csv\"  # Replace with the actual path\n",
    "df = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode the target variable\n",
    "# df['Motor_ON'] = df['Motor_ON'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# # Select features and target\n",
    "# features = df.drop(['Motor_ON', 'Crop'], axis=1)  # Drop 'Crop' if irrelevant\n",
    "# target = df['Motor_ON']\n",
    "\n",
    "# # Normalize the features\n",
    "# scaler = StandardScaler()\n",
    "# features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# # Split the dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>Soil_Moisture (%)</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Nitrogen (mg/kg)</th>\n",
       "      <th>Phosphorus (mg/kg)</th>\n",
       "      <th>Potassium (mg/kg)</th>\n",
       "      <th>Root_Depth (cm)</th>\n",
       "      <th>Water_Needs (L/m²)</th>\n",
       "      <th>Irrigation</th>\n",
       "      <th>Solar_Radiation (W/m²)</th>\n",
       "      <th>Wind_Speed (m/s)</th>\n",
       "      <th>Rainfall (mm/day)</th>\n",
       "      <th>Motor_ON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>54.86</td>\n",
       "      <td>18.04</td>\n",
       "      <td>62.97</td>\n",
       "      <td>125.60</td>\n",
       "      <td>19.08</td>\n",
       "      <td>46.66</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>255.73</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.87</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>38.38</td>\n",
       "      <td>22.44</td>\n",
       "      <td>60.50</td>\n",
       "      <td>20.50</td>\n",
       "      <td>42.68</td>\n",
       "      <td>41.97</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>229.86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.33</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>34.92</td>\n",
       "      <td>18.80</td>\n",
       "      <td>69.60</td>\n",
       "      <td>64.10</td>\n",
       "      <td>11.82</td>\n",
       "      <td>56.63</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>691.91</td>\n",
       "      <td>4.51</td>\n",
       "      <td>12.66</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.59</td>\n",
       "      <td>15.58</td>\n",
       "      <td>72.32</td>\n",
       "      <td>175.10</td>\n",
       "      <td>18.96</td>\n",
       "      <td>67.94</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>511.54</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.48</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.32</td>\n",
       "      <td>19.58</td>\n",
       "      <td>62.36</td>\n",
       "      <td>164.27</td>\n",
       "      <td>53.61</td>\n",
       "      <td>24.68</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>562.13</td>\n",
       "      <td>0.97</td>\n",
       "      <td>19.73</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Crop  Soil_Moisture (%)  Temperature (°C)  Humidity (%)  Nitrogen (mg/kg)  \\\n",
       "0  Wheat              54.86             18.04         62.97            125.60   \n",
       "1  Wheat              38.38             22.44         60.50             20.50   \n",
       "2  Wheat              34.92             18.80         69.60             64.10   \n",
       "3  Wheat              30.59             15.58         72.32            175.10   \n",
       "4  Wheat              30.32             19.58         62.36            164.27   \n",
       "\n",
       "   Phosphorus (mg/kg)  Potassium (mg/kg)  Root_Depth (cm)  Water_Needs (L/m²)  \\\n",
       "0               19.08              46.66               60                   4   \n",
       "1               42.68              41.97               60                   4   \n",
       "2               11.82              56.63               60                   4   \n",
       "3               18.96              67.94               60                   4   \n",
       "4               53.61              24.68               60                   4   \n",
       "\n",
       "  Irrigation  Solar_Radiation (W/m²)  Wind_Speed (m/s)  Rainfall (mm/day)  \\\n",
       "0         No                  255.73              2.68              13.87   \n",
       "1         No                  229.86              2.95               2.33   \n",
       "2         No                  691.91              4.51              12.66   \n",
       "3         No                  511.54              4.66               2.48   \n",
       "4         No                  562.13              0.97              19.73   \n",
       "\n",
       "  Motor_ON  \n",
       "0       No  \n",
       "1       No  \n",
       "2       No  \n",
       "3       No  \n",
       "4       No  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crop                      0\n",
       "Soil_Moisture (%)         0\n",
       "Temperature (°C)          0\n",
       "Humidity (%)              0\n",
       "Nitrogen (mg/kg)          0\n",
       "Phosphorus (mg/kg)        0\n",
       "Potassium (mg/kg)         0\n",
       "Root_Depth (cm)           0\n",
       "Water_Needs (L/m²)        0\n",
       "Irrigation                0\n",
       "Solar_Radiation (W/m²)    0\n",
       "Wind_Speed (m/s)          0\n",
       "Rainfall (mm/day)         0\n",
       "Motor_ON                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Wheat'], dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Crop'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Crop'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "24995    1\n",
       "24996    1\n",
       "24997    1\n",
       "24998    1\n",
       "24999    1\n",
       "Name: Crop, Length: 25000, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Crop'].map({\"Wheat\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>Soil_Moisture (%)</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Nitrogen (mg/kg)</th>\n",
       "      <th>Phosphorus (mg/kg)</th>\n",
       "      <th>Potassium (mg/kg)</th>\n",
       "      <th>Root_Depth (cm)</th>\n",
       "      <th>Water_Needs (L/m²)</th>\n",
       "      <th>Irrigation</th>\n",
       "      <th>Solar_Radiation (W/m²)</th>\n",
       "      <th>Wind_Speed (m/s)</th>\n",
       "      <th>Rainfall (mm/day)</th>\n",
       "      <th>Motor_ON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>54.86</td>\n",
       "      <td>18.04</td>\n",
       "      <td>62.97</td>\n",
       "      <td>125.60</td>\n",
       "      <td>19.08</td>\n",
       "      <td>46.66</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>255.73</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.87</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>38.38</td>\n",
       "      <td>22.44</td>\n",
       "      <td>60.50</td>\n",
       "      <td>20.50</td>\n",
       "      <td>42.68</td>\n",
       "      <td>41.97</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>229.86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.33</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>34.92</td>\n",
       "      <td>18.80</td>\n",
       "      <td>69.60</td>\n",
       "      <td>64.10</td>\n",
       "      <td>11.82</td>\n",
       "      <td>56.63</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>691.91</td>\n",
       "      <td>4.51</td>\n",
       "      <td>12.66</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.59</td>\n",
       "      <td>15.58</td>\n",
       "      <td>72.32</td>\n",
       "      <td>175.10</td>\n",
       "      <td>18.96</td>\n",
       "      <td>67.94</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>511.54</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.48</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.32</td>\n",
       "      <td>19.58</td>\n",
       "      <td>62.36</td>\n",
       "      <td>164.27</td>\n",
       "      <td>53.61</td>\n",
       "      <td>24.68</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>562.13</td>\n",
       "      <td>0.97</td>\n",
       "      <td>19.73</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Crop  Soil_Moisture (%)  Temperature (°C)  Humidity (%)  Nitrogen (mg/kg)  \\\n",
       "0  Wheat              54.86             18.04         62.97            125.60   \n",
       "1  Wheat              38.38             22.44         60.50             20.50   \n",
       "2  Wheat              34.92             18.80         69.60             64.10   \n",
       "3  Wheat              30.59             15.58         72.32            175.10   \n",
       "4  Wheat              30.32             19.58         62.36            164.27   \n",
       "\n",
       "   Phosphorus (mg/kg)  Potassium (mg/kg)  Root_Depth (cm)  Water_Needs (L/m²)  \\\n",
       "0               19.08              46.66               60                   4   \n",
       "1               42.68              41.97               60                   4   \n",
       "2               11.82              56.63               60                   4   \n",
       "3               18.96              67.94               60                   4   \n",
       "4               53.61              24.68               60                   4   \n",
       "\n",
       "  Irrigation  Solar_Radiation (W/m²)  Wind_Speed (m/s)  Rainfall (mm/day)  \\\n",
       "0         No                  255.73              2.68              13.87   \n",
       "1         No                  229.86              2.95               2.33   \n",
       "2         No                  691.91              4.51              12.66   \n",
       "3         No                  511.54              4.66               2.48   \n",
       "4         No                  562.13              0.97              19.73   \n",
       "\n",
       "  Motor_ON  \n",
       "0       No  \n",
       "1       No  \n",
       "2       No  \n",
       "3       No  \n",
       "4       No  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>Soil_Moisture (%)</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Nitrogen (mg/kg)</th>\n",
       "      <th>Phosphorus (mg/kg)</th>\n",
       "      <th>Potassium (mg/kg)</th>\n",
       "      <th>Root_Depth (cm)</th>\n",
       "      <th>Water_Needs (L/m²)</th>\n",
       "      <th>Irrigation</th>\n",
       "      <th>Solar_Radiation (W/m²)</th>\n",
       "      <th>Wind_Speed (m/s)</th>\n",
       "      <th>Rainfall (mm/day)</th>\n",
       "      <th>Motor_ON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>54.86</td>\n",
       "      <td>18.04</td>\n",
       "      <td>62.97</td>\n",
       "      <td>125.60</td>\n",
       "      <td>19.08</td>\n",
       "      <td>46.66</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>255.73</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.87</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>38.38</td>\n",
       "      <td>22.44</td>\n",
       "      <td>60.50</td>\n",
       "      <td>20.50</td>\n",
       "      <td>42.68</td>\n",
       "      <td>41.97</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>229.86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.33</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>34.92</td>\n",
       "      <td>18.80</td>\n",
       "      <td>69.60</td>\n",
       "      <td>64.10</td>\n",
       "      <td>11.82</td>\n",
       "      <td>56.63</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>691.91</td>\n",
       "      <td>4.51</td>\n",
       "      <td>12.66</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.59</td>\n",
       "      <td>15.58</td>\n",
       "      <td>72.32</td>\n",
       "      <td>175.10</td>\n",
       "      <td>18.96</td>\n",
       "      <td>67.94</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>511.54</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.48</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.32</td>\n",
       "      <td>19.58</td>\n",
       "      <td>62.36</td>\n",
       "      <td>164.27</td>\n",
       "      <td>53.61</td>\n",
       "      <td>24.68</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>562.13</td>\n",
       "      <td>0.97</td>\n",
       "      <td>19.73</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Crop  Soil_Moisture (%)  Temperature (°C)  Humidity (%)  Nitrogen (mg/kg)  \\\n",
       "0  Wheat              54.86             18.04         62.97            125.60   \n",
       "1  Wheat              38.38             22.44         60.50             20.50   \n",
       "2  Wheat              34.92             18.80         69.60             64.10   \n",
       "3  Wheat              30.59             15.58         72.32            175.10   \n",
       "4  Wheat              30.32             19.58         62.36            164.27   \n",
       "\n",
       "   Phosphorus (mg/kg)  Potassium (mg/kg)  Root_Depth (cm)  Water_Needs (L/m²)  \\\n",
       "0               19.08              46.66               60                   4   \n",
       "1               42.68              41.97               60                   4   \n",
       "2               11.82              56.63               60                   4   \n",
       "3               18.96              67.94               60                   4   \n",
       "4               53.61              24.68               60                   4   \n",
       "\n",
       "  Irrigation  Solar_Radiation (W/m²)  Wind_Speed (m/s)  Rainfall (mm/day)  \\\n",
       "0         No                  255.73              2.68              13.87   \n",
       "1         No                  229.86              2.95               2.33   \n",
       "2         No                  691.91              4.51              12.66   \n",
       "3         No                  511.54              4.66               2.48   \n",
       "4         No                  562.13              0.97              19.73   \n",
       "\n",
       "  Motor_ON  \n",
       "0       No  \n",
       "1       No  \n",
       "2       No  \n",
       "3       No  \n",
       "4       No  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Motor_ON'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "24995    0\n",
       "24996    0\n",
       "24997    0\n",
       "24998    1\n",
       "24999    0\n",
       "Name: Irrigation, Length: 25000, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Irrigation'].map({'Yes':1 , 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>Soil_Moisture (%)</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Nitrogen (mg/kg)</th>\n",
       "      <th>Phosphorus (mg/kg)</th>\n",
       "      <th>Potassium (mg/kg)</th>\n",
       "      <th>Root_Depth (cm)</th>\n",
       "      <th>Water_Needs (L/m²)</th>\n",
       "      <th>Irrigation</th>\n",
       "      <th>Solar_Radiation (W/m²)</th>\n",
       "      <th>Wind_Speed (m/s)</th>\n",
       "      <th>Rainfall (mm/day)</th>\n",
       "      <th>Motor_ON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>54.86</td>\n",
       "      <td>18.04</td>\n",
       "      <td>62.97</td>\n",
       "      <td>125.60</td>\n",
       "      <td>19.08</td>\n",
       "      <td>46.66</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>255.73</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.87</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>38.38</td>\n",
       "      <td>22.44</td>\n",
       "      <td>60.50</td>\n",
       "      <td>20.50</td>\n",
       "      <td>42.68</td>\n",
       "      <td>41.97</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>229.86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.33</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>34.92</td>\n",
       "      <td>18.80</td>\n",
       "      <td>69.60</td>\n",
       "      <td>64.10</td>\n",
       "      <td>11.82</td>\n",
       "      <td>56.63</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>691.91</td>\n",
       "      <td>4.51</td>\n",
       "      <td>12.66</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.59</td>\n",
       "      <td>15.58</td>\n",
       "      <td>72.32</td>\n",
       "      <td>175.10</td>\n",
       "      <td>18.96</td>\n",
       "      <td>67.94</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>511.54</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.48</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.32</td>\n",
       "      <td>19.58</td>\n",
       "      <td>62.36</td>\n",
       "      <td>164.27</td>\n",
       "      <td>53.61</td>\n",
       "      <td>24.68</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>562.13</td>\n",
       "      <td>0.97</td>\n",
       "      <td>19.73</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Crop  Soil_Moisture (%)  Temperature (°C)  Humidity (%)  Nitrogen (mg/kg)  \\\n",
       "0  Wheat              54.86             18.04         62.97            125.60   \n",
       "1  Wheat              38.38             22.44         60.50             20.50   \n",
       "2  Wheat              34.92             18.80         69.60             64.10   \n",
       "3  Wheat              30.59             15.58         72.32            175.10   \n",
       "4  Wheat              30.32             19.58         62.36            164.27   \n",
       "\n",
       "   Phosphorus (mg/kg)  Potassium (mg/kg)  Root_Depth (cm)  Water_Needs (L/m²)  \\\n",
       "0               19.08              46.66               60                   4   \n",
       "1               42.68              41.97               60                   4   \n",
       "2               11.82              56.63               60                   4   \n",
       "3               18.96              67.94               60                   4   \n",
       "4               53.61              24.68               60                   4   \n",
       "\n",
       "  Irrigation  Solar_Radiation (W/m²)  Wind_Speed (m/s)  Rainfall (mm/day)  \\\n",
       "0         No                  255.73              2.68              13.87   \n",
       "1         No                  229.86              2.95               2.33   \n",
       "2         No                  691.91              4.51              12.66   \n",
       "3         No                  511.54              4.66               2.48   \n",
       "4         No                  562.13              0.97              19.73   \n",
       "\n",
       "  Motor_ON  \n",
       "0       No  \n",
       "1       No  \n",
       "2       No  \n",
       "3       No  \n",
       "4       No  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>soil_moisture</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>root_depth</th>\n",
       "      <th>water_need</th>\n",
       "      <th>Irrigation</th>\n",
       "      <th>s_radiation</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>54.86</td>\n",
       "      <td>18.04</td>\n",
       "      <td>62.97</td>\n",
       "      <td>125.60</td>\n",
       "      <td>19.08</td>\n",
       "      <td>46.66</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>255.73</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.87</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>38.38</td>\n",
       "      <td>22.44</td>\n",
       "      <td>60.50</td>\n",
       "      <td>20.50</td>\n",
       "      <td>42.68</td>\n",
       "      <td>41.97</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>229.86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.33</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>34.92</td>\n",
       "      <td>18.80</td>\n",
       "      <td>69.60</td>\n",
       "      <td>64.10</td>\n",
       "      <td>11.82</td>\n",
       "      <td>56.63</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>691.91</td>\n",
       "      <td>4.51</td>\n",
       "      <td>12.66</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.59</td>\n",
       "      <td>15.58</td>\n",
       "      <td>72.32</td>\n",
       "      <td>175.10</td>\n",
       "      <td>18.96</td>\n",
       "      <td>67.94</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>511.54</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.48</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.32</td>\n",
       "      <td>19.58</td>\n",
       "      <td>62.36</td>\n",
       "      <td>164.27</td>\n",
       "      <td>53.61</td>\n",
       "      <td>24.68</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>562.13</td>\n",
       "      <td>0.97</td>\n",
       "      <td>19.73</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Crop  soil_moisture   temp  humidity       N      P      K  root_depth  \\\n",
       "0  Wheat          54.86  18.04     62.97  125.60  19.08  46.66          60   \n",
       "1  Wheat          38.38  22.44     60.50   20.50  42.68  41.97          60   \n",
       "2  Wheat          34.92  18.80     69.60   64.10  11.82  56.63          60   \n",
       "3  Wheat          30.59  15.58     72.32  175.10  18.96  67.94          60   \n",
       "4  Wheat          30.32  19.58     62.36  164.27  53.61  24.68          60   \n",
       "\n",
       "   water_need Irrigation  s_radiation  wind_speed  rainfall status  \n",
       "0           4         No       255.73        2.68     13.87     No  \n",
       "1           4         No       229.86        2.95      2.33     No  \n",
       "2           4         No       691.91        4.51     12.66     No  \n",
       "3           4         No       511.54        4.66      2.48     No  \n",
       "4           4         No       562.13        0.97     19.73     No  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df_copy.rename(columns= {\n",
    "                                   \"Soil_Moisture (%)\":\"soil_moisture\",\n",
    "                                   \"Temperature (°C)\":\"temp\",\n",
    "                                   \"Humidity (%)\":\"humidity\",\n",
    "                                   \"Nitrogen (mg/kg)\":\"N\",\n",
    "                                   \"Phosphorus (mg/kg)\":\"P\",\n",
    "                                   \"Potassium (mg/kg)\":\"K\",\n",
    "                                   \"Root_Depth (cm)\":\"root_depth\",\n",
    "                                   \"Solar_Radiation (W/m²)\":\"s_radiation\",\n",
    "                                   \"Water_Needs (L/m²)\":\"water_need\",\n",
    "                                   \"Wind_Speed (m/s)\":\"wind_speed\",\n",
    "                                   \"Rainfall (mm/day)\":\"rainfall\",\n",
    "                                   \"Motor_ON\": \"status\"\n",
    "                         \n",
    "                         })\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>soil_moisture</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>water_need</th>\n",
       "      <th>Irrigation</th>\n",
       "      <th>s_radiation</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>54.86</td>\n",
       "      <td>18.04</td>\n",
       "      <td>62.97</td>\n",
       "      <td>125.60</td>\n",
       "      <td>19.08</td>\n",
       "      <td>46.66</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>255.73</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.87</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>38.38</td>\n",
       "      <td>22.44</td>\n",
       "      <td>60.50</td>\n",
       "      <td>20.50</td>\n",
       "      <td>42.68</td>\n",
       "      <td>41.97</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>229.86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.33</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>34.92</td>\n",
       "      <td>18.80</td>\n",
       "      <td>69.60</td>\n",
       "      <td>64.10</td>\n",
       "      <td>11.82</td>\n",
       "      <td>56.63</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>691.91</td>\n",
       "      <td>4.51</td>\n",
       "      <td>12.66</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.59</td>\n",
       "      <td>15.58</td>\n",
       "      <td>72.32</td>\n",
       "      <td>175.10</td>\n",
       "      <td>18.96</td>\n",
       "      <td>67.94</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>511.54</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.48</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>30.32</td>\n",
       "      <td>19.58</td>\n",
       "      <td>62.36</td>\n",
       "      <td>164.27</td>\n",
       "      <td>53.61</td>\n",
       "      <td>24.68</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>562.13</td>\n",
       "      <td>0.97</td>\n",
       "      <td>19.73</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>56.00</td>\n",
       "      <td>23.42</td>\n",
       "      <td>65.76</td>\n",
       "      <td>199.18</td>\n",
       "      <td>49.84</td>\n",
       "      <td>49.93</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>404.87</td>\n",
       "      <td>1.43</td>\n",
       "      <td>4.59</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>56.79</td>\n",
       "      <td>11.24</td>\n",
       "      <td>52.01</td>\n",
       "      <td>126.12</td>\n",
       "      <td>52.82</td>\n",
       "      <td>67.39</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>730.18</td>\n",
       "      <td>3.86</td>\n",
       "      <td>9.02</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>38.83</td>\n",
       "      <td>20.98</td>\n",
       "      <td>77.25</td>\n",
       "      <td>184.46</td>\n",
       "      <td>20.59</td>\n",
       "      <td>19.66</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>649.94</td>\n",
       "      <td>1.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>23.85</td>\n",
       "      <td>14.67</td>\n",
       "      <td>53.42</td>\n",
       "      <td>40.80</td>\n",
       "      <td>51.32</td>\n",
       "      <td>32.56</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>278.54</td>\n",
       "      <td>4.55</td>\n",
       "      <td>8.44</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>34.08</td>\n",
       "      <td>23.36</td>\n",
       "      <td>67.77</td>\n",
       "      <td>45.00</td>\n",
       "      <td>54.67</td>\n",
       "      <td>21.26</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>529.12</td>\n",
       "      <td>2.82</td>\n",
       "      <td>7.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Crop  soil_moisture   temp  humidity       N      P      K  \\\n",
       "0      Wheat          54.86  18.04     62.97  125.60  19.08  46.66   \n",
       "1      Wheat          38.38  22.44     60.50   20.50  42.68  41.97   \n",
       "2      Wheat          34.92  18.80     69.60   64.10  11.82  56.63   \n",
       "3      Wheat          30.59  15.58     72.32  175.10  18.96  67.94   \n",
       "4      Wheat          30.32  19.58     62.36  164.27  53.61  24.68   \n",
       "...      ...            ...    ...       ...     ...    ...    ...   \n",
       "24995  Wheat          56.00  23.42     65.76  199.18  49.84  49.93   \n",
       "24996  Wheat          56.79  11.24     52.01  126.12  52.82  67.39   \n",
       "24997  Wheat          38.83  20.98     77.25  184.46  20.59  19.66   \n",
       "24998  Wheat          23.85  14.67     53.42   40.80  51.32  32.56   \n",
       "24999  Wheat          34.08  23.36     67.77   45.00  54.67  21.26   \n",
       "\n",
       "       water_need Irrigation  s_radiation  wind_speed  rainfall status  \n",
       "0               4         No       255.73        2.68     13.87     No  \n",
       "1               4         No       229.86        2.95      2.33     No  \n",
       "2               4         No       691.91        4.51     12.66     No  \n",
       "3               4         No       511.54        4.66      2.48     No  \n",
       "4               4         No       562.13        0.97     19.73     No  \n",
       "...           ...        ...          ...         ...       ...    ...  \n",
       "24995           4         No       404.87        1.43      4.59     No  \n",
       "24996           4         No       730.18        3.86      9.02     No  \n",
       "24997           4         No       649.94        1.20     10.53     No  \n",
       "24998           4        Yes       278.54        4.55      8.44    Yes  \n",
       "24999           4         No       529.12        2.82      7.85     No  \n",
       "\n",
       "[25000 rows x 13 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df_copy.drop(columns={'root_depth'}, axis =1 )\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soil_moisture</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>water_need</th>\n",
       "      <th>Irrigation</th>\n",
       "      <th>s_radiation</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.86</td>\n",
       "      <td>18.04</td>\n",
       "      <td>62.97</td>\n",
       "      <td>125.60</td>\n",
       "      <td>19.08</td>\n",
       "      <td>46.66</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>255.73</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.87</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.38</td>\n",
       "      <td>22.44</td>\n",
       "      <td>60.50</td>\n",
       "      <td>20.50</td>\n",
       "      <td>42.68</td>\n",
       "      <td>41.97</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>229.86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.33</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.92</td>\n",
       "      <td>18.80</td>\n",
       "      <td>69.60</td>\n",
       "      <td>64.10</td>\n",
       "      <td>11.82</td>\n",
       "      <td>56.63</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>691.91</td>\n",
       "      <td>4.51</td>\n",
       "      <td>12.66</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.59</td>\n",
       "      <td>15.58</td>\n",
       "      <td>72.32</td>\n",
       "      <td>175.10</td>\n",
       "      <td>18.96</td>\n",
       "      <td>67.94</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>511.54</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.48</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.32</td>\n",
       "      <td>19.58</td>\n",
       "      <td>62.36</td>\n",
       "      <td>164.27</td>\n",
       "      <td>53.61</td>\n",
       "      <td>24.68</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>562.13</td>\n",
       "      <td>0.97</td>\n",
       "      <td>19.73</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>56.00</td>\n",
       "      <td>23.42</td>\n",
       "      <td>65.76</td>\n",
       "      <td>199.18</td>\n",
       "      <td>49.84</td>\n",
       "      <td>49.93</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>404.87</td>\n",
       "      <td>1.43</td>\n",
       "      <td>4.59</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>56.79</td>\n",
       "      <td>11.24</td>\n",
       "      <td>52.01</td>\n",
       "      <td>126.12</td>\n",
       "      <td>52.82</td>\n",
       "      <td>67.39</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>730.18</td>\n",
       "      <td>3.86</td>\n",
       "      <td>9.02</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>38.83</td>\n",
       "      <td>20.98</td>\n",
       "      <td>77.25</td>\n",
       "      <td>184.46</td>\n",
       "      <td>20.59</td>\n",
       "      <td>19.66</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>649.94</td>\n",
       "      <td>1.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>23.85</td>\n",
       "      <td>14.67</td>\n",
       "      <td>53.42</td>\n",
       "      <td>40.80</td>\n",
       "      <td>51.32</td>\n",
       "      <td>32.56</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>278.54</td>\n",
       "      <td>4.55</td>\n",
       "      <td>8.44</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>34.08</td>\n",
       "      <td>23.36</td>\n",
       "      <td>67.77</td>\n",
       "      <td>45.00</td>\n",
       "      <td>54.67</td>\n",
       "      <td>21.26</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>529.12</td>\n",
       "      <td>2.82</td>\n",
       "      <td>7.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       soil_moisture   temp  humidity       N      P      K  water_need  \\\n",
       "0              54.86  18.04     62.97  125.60  19.08  46.66           4   \n",
       "1              38.38  22.44     60.50   20.50  42.68  41.97           4   \n",
       "2              34.92  18.80     69.60   64.10  11.82  56.63           4   \n",
       "3              30.59  15.58     72.32  175.10  18.96  67.94           4   \n",
       "4              30.32  19.58     62.36  164.27  53.61  24.68           4   \n",
       "...              ...    ...       ...     ...    ...    ...         ...   \n",
       "24995          56.00  23.42     65.76  199.18  49.84  49.93           4   \n",
       "24996          56.79  11.24     52.01  126.12  52.82  67.39           4   \n",
       "24997          38.83  20.98     77.25  184.46  20.59  19.66           4   \n",
       "24998          23.85  14.67     53.42   40.80  51.32  32.56           4   \n",
       "24999          34.08  23.36     67.77   45.00  54.67  21.26           4   \n",
       "\n",
       "      Irrigation  s_radiation  wind_speed  rainfall status  \n",
       "0             No       255.73        2.68     13.87     No  \n",
       "1             No       229.86        2.95      2.33     No  \n",
       "2             No       691.91        4.51     12.66     No  \n",
       "3             No       511.54        4.66      2.48     No  \n",
       "4             No       562.13        0.97     19.73     No  \n",
       "...          ...          ...         ...       ...    ...  \n",
       "24995         No       404.87        1.43      4.59     No  \n",
       "24996         No       730.18        3.86      9.02     No  \n",
       "24997         No       649.94        1.20     10.53     No  \n",
       "24998        Yes       278.54        4.55      8.44    Yes  \n",
       "24999         No       529.12        2.82      7.85     No  \n",
       "\n",
       "[25000 rows x 12 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df_copy.drop(columns={'Crop'}, axis =1 )\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soil_moisture</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>Irrigation</th>\n",
       "      <th>s_radiation</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.86</td>\n",
       "      <td>18.04</td>\n",
       "      <td>62.97</td>\n",
       "      <td>125.60</td>\n",
       "      <td>19.08</td>\n",
       "      <td>46.66</td>\n",
       "      <td>No</td>\n",
       "      <td>255.73</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.87</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.38</td>\n",
       "      <td>22.44</td>\n",
       "      <td>60.50</td>\n",
       "      <td>20.50</td>\n",
       "      <td>42.68</td>\n",
       "      <td>41.97</td>\n",
       "      <td>No</td>\n",
       "      <td>229.86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.33</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.92</td>\n",
       "      <td>18.80</td>\n",
       "      <td>69.60</td>\n",
       "      <td>64.10</td>\n",
       "      <td>11.82</td>\n",
       "      <td>56.63</td>\n",
       "      <td>No</td>\n",
       "      <td>691.91</td>\n",
       "      <td>4.51</td>\n",
       "      <td>12.66</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.59</td>\n",
       "      <td>15.58</td>\n",
       "      <td>72.32</td>\n",
       "      <td>175.10</td>\n",
       "      <td>18.96</td>\n",
       "      <td>67.94</td>\n",
       "      <td>No</td>\n",
       "      <td>511.54</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.48</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.32</td>\n",
       "      <td>19.58</td>\n",
       "      <td>62.36</td>\n",
       "      <td>164.27</td>\n",
       "      <td>53.61</td>\n",
       "      <td>24.68</td>\n",
       "      <td>No</td>\n",
       "      <td>562.13</td>\n",
       "      <td>0.97</td>\n",
       "      <td>19.73</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>56.00</td>\n",
       "      <td>23.42</td>\n",
       "      <td>65.76</td>\n",
       "      <td>199.18</td>\n",
       "      <td>49.84</td>\n",
       "      <td>49.93</td>\n",
       "      <td>No</td>\n",
       "      <td>404.87</td>\n",
       "      <td>1.43</td>\n",
       "      <td>4.59</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>56.79</td>\n",
       "      <td>11.24</td>\n",
       "      <td>52.01</td>\n",
       "      <td>126.12</td>\n",
       "      <td>52.82</td>\n",
       "      <td>67.39</td>\n",
       "      <td>No</td>\n",
       "      <td>730.18</td>\n",
       "      <td>3.86</td>\n",
       "      <td>9.02</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>38.83</td>\n",
       "      <td>20.98</td>\n",
       "      <td>77.25</td>\n",
       "      <td>184.46</td>\n",
       "      <td>20.59</td>\n",
       "      <td>19.66</td>\n",
       "      <td>No</td>\n",
       "      <td>649.94</td>\n",
       "      <td>1.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>23.85</td>\n",
       "      <td>14.67</td>\n",
       "      <td>53.42</td>\n",
       "      <td>40.80</td>\n",
       "      <td>51.32</td>\n",
       "      <td>32.56</td>\n",
       "      <td>Yes</td>\n",
       "      <td>278.54</td>\n",
       "      <td>4.55</td>\n",
       "      <td>8.44</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>34.08</td>\n",
       "      <td>23.36</td>\n",
       "      <td>67.77</td>\n",
       "      <td>45.00</td>\n",
       "      <td>54.67</td>\n",
       "      <td>21.26</td>\n",
       "      <td>No</td>\n",
       "      <td>529.12</td>\n",
       "      <td>2.82</td>\n",
       "      <td>7.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       soil_moisture   temp  humidity       N      P      K Irrigation  \\\n",
       "0              54.86  18.04     62.97  125.60  19.08  46.66         No   \n",
       "1              38.38  22.44     60.50   20.50  42.68  41.97         No   \n",
       "2              34.92  18.80     69.60   64.10  11.82  56.63         No   \n",
       "3              30.59  15.58     72.32  175.10  18.96  67.94         No   \n",
       "4              30.32  19.58     62.36  164.27  53.61  24.68         No   \n",
       "...              ...    ...       ...     ...    ...    ...        ...   \n",
       "24995          56.00  23.42     65.76  199.18  49.84  49.93         No   \n",
       "24996          56.79  11.24     52.01  126.12  52.82  67.39         No   \n",
       "24997          38.83  20.98     77.25  184.46  20.59  19.66         No   \n",
       "24998          23.85  14.67     53.42   40.80  51.32  32.56        Yes   \n",
       "24999          34.08  23.36     67.77   45.00  54.67  21.26         No   \n",
       "\n",
       "       s_radiation  wind_speed  rainfall status  \n",
       "0           255.73        2.68     13.87     No  \n",
       "1           229.86        2.95      2.33     No  \n",
       "2           691.91        4.51     12.66     No  \n",
       "3           511.54        4.66      2.48     No  \n",
       "4           562.13        0.97     19.73     No  \n",
       "...            ...         ...       ...    ...  \n",
       "24995       404.87        1.43      4.59     No  \n",
       "24996       730.18        3.86      9.02     No  \n",
       "24997       649.94        1.20     10.53     No  \n",
       "24998       278.54        4.55      8.44    Yes  \n",
       "24999       529.12        2.82      7.85     No  \n",
       "\n",
       "[25000 rows x 11 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df_copy.drop(columns={'water_need'}, axis =1 )\n",
    "df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Irrigation'] = df_copy['Irrigation'].map({'Yes':1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['status'] = df_copy['status'].map({\"Yes\": 1, 'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soil_moisture</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>Irrigation</th>\n",
       "      <th>s_radiation</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.86</td>\n",
       "      <td>18.04</td>\n",
       "      <td>62.97</td>\n",
       "      <td>125.60</td>\n",
       "      <td>19.08</td>\n",
       "      <td>46.66</td>\n",
       "      <td>0</td>\n",
       "      <td>255.73</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.38</td>\n",
       "      <td>22.44</td>\n",
       "      <td>60.50</td>\n",
       "      <td>20.50</td>\n",
       "      <td>42.68</td>\n",
       "      <td>41.97</td>\n",
       "      <td>0</td>\n",
       "      <td>229.86</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.92</td>\n",
       "      <td>18.80</td>\n",
       "      <td>69.60</td>\n",
       "      <td>64.10</td>\n",
       "      <td>11.82</td>\n",
       "      <td>56.63</td>\n",
       "      <td>0</td>\n",
       "      <td>691.91</td>\n",
       "      <td>4.51</td>\n",
       "      <td>12.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.59</td>\n",
       "      <td>15.58</td>\n",
       "      <td>72.32</td>\n",
       "      <td>175.10</td>\n",
       "      <td>18.96</td>\n",
       "      <td>67.94</td>\n",
       "      <td>0</td>\n",
       "      <td>511.54</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.32</td>\n",
       "      <td>19.58</td>\n",
       "      <td>62.36</td>\n",
       "      <td>164.27</td>\n",
       "      <td>53.61</td>\n",
       "      <td>24.68</td>\n",
       "      <td>0</td>\n",
       "      <td>562.13</td>\n",
       "      <td>0.97</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>56.00</td>\n",
       "      <td>23.42</td>\n",
       "      <td>65.76</td>\n",
       "      <td>199.18</td>\n",
       "      <td>49.84</td>\n",
       "      <td>49.93</td>\n",
       "      <td>0</td>\n",
       "      <td>404.87</td>\n",
       "      <td>1.43</td>\n",
       "      <td>4.59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>56.79</td>\n",
       "      <td>11.24</td>\n",
       "      <td>52.01</td>\n",
       "      <td>126.12</td>\n",
       "      <td>52.82</td>\n",
       "      <td>67.39</td>\n",
       "      <td>0</td>\n",
       "      <td>730.18</td>\n",
       "      <td>3.86</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>38.83</td>\n",
       "      <td>20.98</td>\n",
       "      <td>77.25</td>\n",
       "      <td>184.46</td>\n",
       "      <td>20.59</td>\n",
       "      <td>19.66</td>\n",
       "      <td>0</td>\n",
       "      <td>649.94</td>\n",
       "      <td>1.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>23.85</td>\n",
       "      <td>14.67</td>\n",
       "      <td>53.42</td>\n",
       "      <td>40.80</td>\n",
       "      <td>51.32</td>\n",
       "      <td>32.56</td>\n",
       "      <td>1</td>\n",
       "      <td>278.54</td>\n",
       "      <td>4.55</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>34.08</td>\n",
       "      <td>23.36</td>\n",
       "      <td>67.77</td>\n",
       "      <td>45.00</td>\n",
       "      <td>54.67</td>\n",
       "      <td>21.26</td>\n",
       "      <td>0</td>\n",
       "      <td>529.12</td>\n",
       "      <td>2.82</td>\n",
       "      <td>7.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       soil_moisture   temp  humidity       N      P      K  Irrigation  \\\n",
       "0              54.86  18.04     62.97  125.60  19.08  46.66           0   \n",
       "1              38.38  22.44     60.50   20.50  42.68  41.97           0   \n",
       "2              34.92  18.80     69.60   64.10  11.82  56.63           0   \n",
       "3              30.59  15.58     72.32  175.10  18.96  67.94           0   \n",
       "4              30.32  19.58     62.36  164.27  53.61  24.68           0   \n",
       "...              ...    ...       ...     ...    ...    ...         ...   \n",
       "24995          56.00  23.42     65.76  199.18  49.84  49.93           0   \n",
       "24996          56.79  11.24     52.01  126.12  52.82  67.39           0   \n",
       "24997          38.83  20.98     77.25  184.46  20.59  19.66           0   \n",
       "24998          23.85  14.67     53.42   40.80  51.32  32.56           1   \n",
       "24999          34.08  23.36     67.77   45.00  54.67  21.26           0   \n",
       "\n",
       "       s_radiation  wind_speed  rainfall  status  \n",
       "0           255.73        2.68     13.87       0  \n",
       "1           229.86        2.95      2.33       0  \n",
       "2           691.91        4.51     12.66       0  \n",
       "3           511.54        4.66      2.48       0  \n",
       "4           562.13        0.97     19.73       0  \n",
       "...            ...         ...       ...     ...  \n",
       "24995       404.87        1.43      4.59       0  \n",
       "24996       730.18        3.86      9.02       0  \n",
       "24997       649.94        1.20     10.53       0  \n",
       "24998       278.54        4.55      8.44       1  \n",
       "24999       529.12        2.82      7.85       0  \n",
       "\n",
       "[25000 rows x 11 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.0\n",
      "max: 20.0\n",
      "median: 10.09\n",
      "mean: 10.0456272\n"
     ]
    }
   ],
   "source": [
    "print(\"min:\",df_copy['rainfall'].min())\n",
    "print(\"max:\",df_copy['rainfall'].max())\n",
    "print(\"median:\",df_copy['rainfall'].median())\n",
    "print(\"mean:\",df_copy['rainfall'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_copy['rainfall'].hist(bins=100)\n",
    "plt.title('Rainfall Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the histogram, the rainfall distribution appears fairly uniform across the range of 0–20. This uniformity suggests that log scaling is not necessary in this case, as there is no skewness or concentration of values in a particular range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min max scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_copy['rainfall_scaled'] = scaler.fit_transform(df_copy[['rainfall']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "columns_to_standardize = ['soil_moisture', 'temp', 'humidity', 'N', 'P', 'K', 's_radiation']\n",
    "df_copy[columns_to_standardize] = scaler.fit_transform(df_copy[columns_to_standardize])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = df_copy.drop(columns=[\"status\"]) \n",
    "y = df_copy[\"status\"]  # Target column\n",
    "\n",
    "# Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_tabular import TabularModel\n",
    "# from pytorch_tabular.config import TabularConfig, DataConfig, ModelConfig, TrainerConfig\n",
    "\n",
    "# # Define configuration for the TabTransformer\n",
    "# data_config = DataConfig(\n",
    "#     target=[\"status\"],\n",
    "#     continuous_cols=continuous_columns,\n",
    "# )\n",
    "\n",
    "# model_config = ModelConfig(\n",
    "#     task=\"classification\",\n",
    "#     layers=\"128-64-32\",  # MLP layers after transformer encoder\n",
    "#     attention_heads=4,\n",
    "#     transformer_layers=3,\n",
    "#     embedding_dim=32,\n",
    "# )\n",
    "\n",
    "# trainer_config = TrainerConfig(\n",
    "#     max_epochs=10,\n",
    "#     gpus=1  # Use \"gpus=1\" if a GPU is available\n",
    "# )\n",
    "\n",
    "# # Combine configurations and initialize the model\n",
    "# config = TabularConfig(\n",
    "#     data_config=data_config,\n",
    "#     model_config=model_config,\n",
    "#     trainer_config=trainer_config,\n",
    "# )\n",
    "\n",
    "# tabular_model = TabularModel(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 0.07366925130334918\n",
      "Epoch 2/1000, Loss: 0.041190779137688455\n",
      "Epoch 3/1000, Loss: 0.04291958403883327\n",
      "Epoch 4/1000, Loss: 0.032037756898955175\n",
      "Epoch 5/1000, Loss: 0.024173926128860795\n",
      "Epoch 6/1000, Loss: 0.01815428197747074\n",
      "Epoch 7/1000, Loss: 0.017578988342024104\n",
      "Epoch 8/1000, Loss: 0.014816061899368354\n",
      "Epoch 9/1000, Loss: 0.01305401399738145\n",
      "Epoch 10/1000, Loss: 0.014537794422693016\n",
      "Epoch 11/1000, Loss: 0.009990393266136856\n",
      "Epoch 12/1000, Loss: 0.009909006872116\n",
      "Epoch 13/1000, Loss: 0.009567934485285702\n",
      "Epoch 14/1000, Loss: 0.009635447008313407\n",
      "Epoch 15/1000, Loss: 0.007979251968906077\n",
      "Epoch 16/1000, Loss: 0.006814109728648922\n",
      "Epoch 17/1000, Loss: 0.006047560281886239\n",
      "Epoch 18/1000, Loss: 0.0055060991377894435\n",
      "Epoch 19/1000, Loss: 0.0065360519433983215\n",
      "Epoch 20/1000, Loss: 0.005681686212239246\n",
      "Epoch 21/1000, Loss: 0.004898611869316265\n",
      "Epoch 22/1000, Loss: 0.004849440298781388\n",
      "Epoch 23/1000, Loss: 0.004695257183867128\n",
      "Epoch 24/1000, Loss: 0.004181263896693106\n",
      "Epoch 25/1000, Loss: 0.00457138254965487\n",
      "Epoch 26/1000, Loss: 0.004013561880210051\n",
      "Epoch 27/1000, Loss: 0.0035039937119262805\n",
      "Epoch 28/1000, Loss: 0.004094110184487014\n",
      "Epoch 29/1000, Loss: 0.003158989122718853\n",
      "Epoch 30/1000, Loss: 0.003154858961398639\n",
      "Epoch 31/1000, Loss: 0.003787401984095668\n",
      "Epoch 32/1000, Loss: 0.0037744312713053054\n",
      "Epoch 33/1000, Loss: 0.0033466885840800517\n",
      "Epoch 34/1000, Loss: 0.0026476653116455223\n",
      "Epoch 35/1000, Loss: 0.0033897662155541997\n",
      "Epoch 36/1000, Loss: 0.003083383587266009\n",
      "Epoch 37/1000, Loss: 0.0030892306678343942\n",
      "Epoch 38/1000, Loss: 0.002834272164268049\n",
      "Epoch 39/1000, Loss: 0.002827269463877907\n",
      "Epoch 40/1000, Loss: 0.002369920471009712\n",
      "Epoch 41/1000, Loss: 0.0027915089543699713\n",
      "Epoch 42/1000, Loss: 0.0028237161967962793\n",
      "Epoch 43/1000, Loss: 0.002782417397809015\n",
      "Epoch 44/1000, Loss: 0.002796762706700033\n",
      "Epoch 45/1000, Loss: 0.0021758633543060408\n",
      "Epoch 46/1000, Loss: 0.0027260412412018946\n",
      "Epoch 47/1000, Loss: 0.0032994959097318506\n",
      "Epoch 48/1000, Loss: 0.0032045200123233513\n",
      "Epoch 49/1000, Loss: 0.002638803741601718\n",
      "Epoch 50/1000, Loss: 0.0024397154416299065\n",
      "Epoch 51/1000, Loss: 0.003779574304929246\n",
      "Epoch 52/1000, Loss: 0.0022982081680619246\n",
      "Epoch 53/1000, Loss: 0.0032394090622444335\n",
      "Epoch 54/1000, Loss: 0.002873164100233821\n",
      "Epoch 55/1000, Loss: 0.0027350249968784543\n",
      "Epoch 56/1000, Loss: 0.0031937719424151145\n",
      "Epoch 57/1000, Loss: 0.0023456791777702306\n",
      "Epoch 58/1000, Loss: 0.0028851642594973077\n",
      "Epoch 59/1000, Loss: 0.003074428016777954\n",
      "Epoch 60/1000, Loss: 0.002772893740477968\n",
      "Epoch 61/1000, Loss: 0.0036520397485980596\n",
      "Epoch 62/1000, Loss: 0.002668030399579442\n",
      "Epoch 63/1000, Loss: 0.0031461313127236646\n",
      "Epoch 64/1000, Loss: 0.0024951310971081026\n",
      "Epoch 65/1000, Loss: 0.00312974969667917\n",
      "Epoch 66/1000, Loss: 0.0034241784065298865\n",
      "Epoch 67/1000, Loss: 0.0032146438560232402\n",
      "Epoch 68/1000, Loss: 0.002797839506665725\n",
      "Epoch 69/1000, Loss: 0.002482439062246434\n",
      "Epoch 70/1000, Loss: 0.0023147265804199647\n",
      "Epoch 71/1000, Loss: 0.003095592169432866\n",
      "Epoch 72/1000, Loss: 0.0026945251151694345\n",
      "Epoch 73/1000, Loss: 0.0026146996928910434\n",
      "Epoch 74/1000, Loss: 0.002900634167827301\n",
      "Epoch 75/1000, Loss: 0.0028895124080717824\n",
      "Epoch 76/1000, Loss: 0.002801754817331917\n",
      "Epoch 77/1000, Loss: 0.0027001555409485057\n",
      "Epoch 78/1000, Loss: 0.0028079000414099383\n",
      "Epoch 79/1000, Loss: 0.002992743808438052\n",
      "Epoch 80/1000, Loss: 0.002905437357656021\n",
      "Epoch 81/1000, Loss: 0.0022896679616946068\n",
      "Epoch 82/1000, Loss: 0.0026632400446096917\n",
      "Epoch 83/1000, Loss: 0.00272386943555766\n",
      "Epoch 84/1000, Loss: 0.002978735272934634\n",
      "Epoch 85/1000, Loss: 0.0023829543629043143\n",
      "Epoch 86/1000, Loss: 0.0026125835187596207\n",
      "Epoch 87/1000, Loss: 0.002858158212439447\n",
      "Epoch 88/1000, Loss: 0.002445517256019346\n",
      "Epoch 89/1000, Loss: 0.002788201104583179\n",
      "Epoch 90/1000, Loss: 0.0029342394660814377\n",
      "Epoch 91/1000, Loss: 0.0024466213085550105\n",
      "Epoch 92/1000, Loss: 0.0021563378235929798\n",
      "Epoch 93/1000, Loss: 0.0030373360857197077\n",
      "Epoch 94/1000, Loss: 0.0025171178814327603\n",
      "Epoch 95/1000, Loss: 0.002663999298248656\n",
      "Epoch 96/1000, Loss: 0.0022088166981713364\n",
      "Epoch 97/1000, Loss: 0.0027649825420527708\n",
      "Epoch 98/1000, Loss: 0.003204649281263565\n",
      "Epoch 99/1000, Loss: 0.0020762316936029333\n",
      "Epoch 100/1000, Loss: 0.0030894647357279075\n",
      "Epoch 101/1000, Loss: 0.0025274819852438377\n",
      "Epoch 102/1000, Loss: 0.002932970449937232\n",
      "Epoch 103/1000, Loss: 0.0029265413826282493\n",
      "Epoch 104/1000, Loss: 0.0029148271151322918\n",
      "Epoch 105/1000, Loss: 0.002663313059774185\n",
      "Epoch 106/1000, Loss: 0.0031071605308838866\n",
      "Epoch 107/1000, Loss: 0.002371729395724052\n",
      "Epoch 108/1000, Loss: 0.002750427331100367\n",
      "Epoch 109/1000, Loss: 0.0027788131720298203\n",
      "Epoch 110/1000, Loss: 0.0027110834653285565\n",
      "Epoch 111/1000, Loss: 0.002441858787052114\n",
      "Epoch 112/1000, Loss: 0.002307649495253481\n",
      "Epoch 113/1000, Loss: 0.002447179538614056\n",
      "Epoch 114/1000, Loss: 0.0029319620387950954\n",
      "Epoch 115/1000, Loss: 0.0022144586776306325\n",
      "Epoch 116/1000, Loss: 0.003048243387217318\n",
      "Epoch 117/1000, Loss: 0.002816086291588113\n",
      "Epoch 118/1000, Loss: 0.0029218249878199504\n",
      "Epoch 119/1000, Loss: 0.00315533244425321\n",
      "Epoch 120/1000, Loss: 0.0030193217915166024\n",
      "Epoch 121/1000, Loss: 0.0025548158958259046\n",
      "Epoch 122/1000, Loss: 0.0024552891823440733\n",
      "Epoch 123/1000, Loss: 0.0027357358812006654\n",
      "Epoch 124/1000, Loss: 0.0032144662221364963\n",
      "Epoch 125/1000, Loss: 0.0031200788563028863\n",
      "Epoch 126/1000, Loss: 0.0026261838718088524\n",
      "Epoch 127/1000, Loss: 0.002767691070356597\n",
      "Epoch 128/1000, Loss: 0.003219241826537617\n",
      "Epoch 129/1000, Loss: 0.00282416653728793\n",
      "Epoch 130/1000, Loss: 0.0030777254271521005\n",
      "Epoch 131/1000, Loss: 0.002653687180184217\n",
      "Epoch 132/1000, Loss: 0.0028419906999789845\n",
      "Epoch 133/1000, Loss: 0.002719507255845204\n",
      "Epoch 134/1000, Loss: 0.002625889921377799\n",
      "Epoch 135/1000, Loss: 0.003179360944568979\n",
      "Epoch 136/1000, Loss: 0.0025972043682375985\n",
      "Epoch 137/1000, Loss: 0.002625180117552728\n",
      "Epoch 138/1000, Loss: 0.002625701351029385\n",
      "Epoch 139/1000, Loss: 0.002573393659428422\n",
      "Epoch 140/1000, Loss: 0.0025256224871554878\n",
      "Epoch 141/1000, Loss: 0.002361301280612365\n",
      "Epoch 142/1000, Loss: 0.0028741398977211803\n",
      "Epoch 143/1000, Loss: 0.0026628421262594143\n",
      "Epoch 144/1000, Loss: 0.003230909457899903\n",
      "Epoch 145/1000, Loss: 0.0028604675139061652\n",
      "Epoch 146/1000, Loss: 0.0035673744430637752\n",
      "Epoch 147/1000, Loss: 0.002641475417377818\n",
      "Epoch 148/1000, Loss: 0.0023251885042334095\n",
      "Epoch 149/1000, Loss: 0.002833600475116891\n",
      "Epoch 150/1000, Loss: 0.0026117344086829548\n",
      "Epoch 151/1000, Loss: 0.002678707872358684\n",
      "Epoch 152/1000, Loss: 0.003348744756347067\n",
      "Epoch 153/1000, Loss: 0.0022643986943027897\n",
      "Epoch 154/1000, Loss: 0.0023274088150665134\n",
      "Epoch 155/1000, Loss: 0.002137680818477544\n",
      "Epoch 156/1000, Loss: 0.002696809959666926\n",
      "Epoch 157/1000, Loss: 0.0026476788469781327\n",
      "Epoch 158/1000, Loss: 0.0027223703459160645\n",
      "Epoch 159/1000, Loss: 0.002823182139804638\n",
      "Epoch 160/1000, Loss: 0.002234709816350685\n",
      "Epoch 161/1000, Loss: 0.0034519606573603333\n",
      "Epoch 162/1000, Loss: 0.00258388372332757\n",
      "Epoch 163/1000, Loss: 0.0023943985432912035\n",
      "Epoch 164/1000, Loss: 0.003317743261754695\n",
      "Epoch 165/1000, Loss: 0.002847442614415232\n",
      "Epoch 166/1000, Loss: 0.0026646036823045746\n",
      "Epoch 167/1000, Loss: 0.0024090456681384797\n",
      "Epoch 168/1000, Loss: 0.0027772932787284575\n",
      "Epoch 169/1000, Loss: 0.0032778234474735014\n",
      "Epoch 170/1000, Loss: 0.002726280944411752\n",
      "Epoch 171/1000, Loss: 0.002605042443602592\n",
      "Epoch 172/1000, Loss: 0.002708656193606268\n",
      "Epoch 173/1000, Loss: 0.0034591848456004457\n",
      "Epoch 174/1000, Loss: 0.0021730795941230885\n",
      "Epoch 175/1000, Loss: 0.003449268691855804\n",
      "Epoch 176/1000, Loss: 0.00295864974158265\n",
      "Epoch 177/1000, Loss: 0.0028513195430741834\n",
      "Epoch 178/1000, Loss: 0.0028657903998923566\n",
      "Epoch 179/1000, Loss: 0.0029559599684833844\n",
      "Epoch 180/1000, Loss: 0.002273228579771165\n",
      "Epoch 181/1000, Loss: 0.0029292867253133273\n",
      "Epoch 182/1000, Loss: 0.002475493484289531\n",
      "Epoch 183/1000, Loss: 0.0030228957064641704\n",
      "Epoch 184/1000, Loss: 0.0035544395530381118\n",
      "Epoch 185/1000, Loss: 0.002955627584857682\n",
      "Epoch 186/1000, Loss: 0.0031681986970789975\n",
      "Epoch 187/1000, Loss: 0.0021214730721391523\n",
      "Epoch 188/1000, Loss: 0.003263028078151275\n",
      "Epoch 189/1000, Loss: 0.002745445570535623\n",
      "Epoch 190/1000, Loss: 0.0025717279017677796\n",
      "Epoch 191/1000, Loss: 0.002794859735380954\n",
      "Epoch 192/1000, Loss: 0.002911080105275123\n",
      "Epoch 193/1000, Loss: 0.0029122155334021\n",
      "Epoch 194/1000, Loss: 0.0026491423560014555\n",
      "Epoch 195/1000, Loss: 0.003007260057253448\n",
      "Epoch 196/1000, Loss: 0.0036607005455885073\n",
      "Epoch 197/1000, Loss: 0.0030248033202393875\n",
      "Epoch 198/1000, Loss: 0.002455875453525338\n",
      "Epoch 199/1000, Loss: 0.0028135675325210614\n",
      "Epoch 200/1000, Loss: 0.002658701265103062\n",
      "Epoch 201/1000, Loss: 0.0033671292777215714\n",
      "Epoch 202/1000, Loss: 0.002712847252448486\n",
      "Epoch 203/1000, Loss: 0.002529682036562333\n",
      "Epoch 204/1000, Loss: 0.003279065710072658\n",
      "Epoch 205/1000, Loss: 0.0023956304442583985\n",
      "Epoch 206/1000, Loss: 0.0021774710342618107\n",
      "Epoch 207/1000, Loss: 0.002675468561650946\n",
      "Epoch 208/1000, Loss: 0.0025922851286981105\n",
      "Epoch 209/1000, Loss: 0.0026867561411429994\n",
      "Epoch 210/1000, Loss: 0.002565796829276514\n",
      "Epoch 211/1000, Loss: 0.0029171729858002487\n",
      "Epoch 212/1000, Loss: 0.0032142732700925023\n",
      "Epoch 213/1000, Loss: 0.002895066144856609\n",
      "Epoch 214/1000, Loss: 0.0032296319006299323\n",
      "Epoch 215/1000, Loss: 0.0032357533090167584\n",
      "Epoch 216/1000, Loss: 0.002514575282254726\n",
      "Epoch 217/1000, Loss: 0.0029661642695947184\n",
      "Epoch 218/1000, Loss: 0.0022478566504887045\n",
      "Epoch 219/1000, Loss: 0.00232350602301665\n",
      "Epoch 220/1000, Loss: 0.002527701183654468\n",
      "Epoch 221/1000, Loss: 0.0025735732312246336\n",
      "Epoch 222/1000, Loss: 0.002394467332675985\n",
      "Epoch 223/1000, Loss: 0.0031841136512699717\n",
      "Epoch 224/1000, Loss: 0.002305412112972366\n",
      "Epoch 225/1000, Loss: 0.002022104221616984\n",
      "Epoch 226/1000, Loss: 0.003106121523648418\n",
      "Epoch 227/1000, Loss: 0.0025322587834424736\n",
      "Epoch 228/1000, Loss: 0.00285555105043508\n",
      "Epoch 229/1000, Loss: 0.0022355015799504076\n",
      "Epoch 230/1000, Loss: 0.0022603570385213542\n",
      "Epoch 231/1000, Loss: 0.0028088364214434148\n",
      "Epoch 232/1000, Loss: 0.0024975269528958698\n",
      "Epoch 233/1000, Loss: 0.00285532985613978\n",
      "Epoch 234/1000, Loss: 0.0031274593702590257\n",
      "Epoch 235/1000, Loss: 0.003148101090159551\n",
      "Epoch 236/1000, Loss: 0.0028182818058298154\n",
      "Epoch 237/1000, Loss: 0.0028323205794110956\n",
      "Epoch 238/1000, Loss: 0.002479696982282068\n",
      "Epoch 239/1000, Loss: 0.0026681992802973973\n",
      "Epoch 240/1000, Loss: 0.0028447638109088138\n",
      "Epoch 241/1000, Loss: 0.002833016575432891\n",
      "Epoch 242/1000, Loss: 0.003095998335749418\n",
      "Epoch 243/1000, Loss: 0.002399928447456029\n",
      "Epoch 244/1000, Loss: 0.002283038955051242\n",
      "Epoch 245/1000, Loss: 0.002500666474844502\n",
      "Epoch 246/1000, Loss: 0.0026943500390316853\n",
      "Epoch 247/1000, Loss: 0.0028831789366292903\n",
      "Epoch 248/1000, Loss: 0.0028072045283792273\n",
      "Epoch 249/1000, Loss: 0.0031187593228653348\n",
      "Epoch 250/1000, Loss: 0.0023043477424111616\n",
      "Epoch 251/1000, Loss: 0.002322773697464357\n",
      "Epoch 252/1000, Loss: 0.0022090925517790102\n",
      "Epoch 253/1000, Loss: 0.002788347818439567\n",
      "Epoch 254/1000, Loss: 0.0022234140003990635\n",
      "Epoch 255/1000, Loss: 0.003346487994163478\n",
      "Epoch 256/1000, Loss: 0.0027818044707327936\n",
      "Epoch 257/1000, Loss: 0.0023039111264444535\n",
      "Epoch 258/1000, Loss: 0.0027712674524349432\n",
      "Epoch 259/1000, Loss: 0.002387758429299959\n",
      "Epoch 260/1000, Loss: 0.003171981530712061\n",
      "Epoch 261/1000, Loss: 0.002739613607094196\n",
      "Epoch 262/1000, Loss: 0.002475718185602213\n",
      "Epoch 263/1000, Loss: 0.0024145782696786237\n",
      "Epoch 264/1000, Loss: 0.0023971666502567326\n",
      "Epoch 265/1000, Loss: 0.0027136741481548357\n",
      "Epoch 266/1000, Loss: 0.0030790903771577604\n",
      "Epoch 267/1000, Loss: 0.0030532525770903913\n",
      "Epoch 268/1000, Loss: 0.0032267897164134996\n",
      "Epoch 269/1000, Loss: 0.0018656487818443797\n",
      "Epoch 270/1000, Loss: 0.002454285101919322\n",
      "Epoch 271/1000, Loss: 0.0027342099622964075\n",
      "Epoch 272/1000, Loss: 0.0027830713722756663\n",
      "Epoch 273/1000, Loss: 0.0021816265092313345\n",
      "Epoch 274/1000, Loss: 0.0024961707560996788\n",
      "Epoch 275/1000, Loss: 0.002649957249114943\n",
      "Epoch 276/1000, Loss: 0.002994851000824037\n",
      "Epoch 277/1000, Loss: 0.0021539778771142892\n",
      "Epoch 278/1000, Loss: 0.002732467707675661\n",
      "Epoch 279/1000, Loss: 0.0027226207074216888\n",
      "Epoch 280/1000, Loss: 0.0024662908448468274\n",
      "Epoch 281/1000, Loss: 0.0024553043478282546\n",
      "Epoch 282/1000, Loss: 0.0030131246534112663\n",
      "Epoch 283/1000, Loss: 0.0023544280084257106\n",
      "Epoch 284/1000, Loss: 0.0022896154536597396\n",
      "Epoch 285/1000, Loss: 0.0031429609682727287\n",
      "Epoch 286/1000, Loss: 0.0029142995526301976\n",
      "Epoch 287/1000, Loss: 0.0027915481417129778\n",
      "Epoch 288/1000, Loss: 0.003187205043357567\n",
      "Epoch 289/1000, Loss: 0.002501063110725889\n",
      "Epoch 290/1000, Loss: 0.0022328729948303035\n",
      "Epoch 291/1000, Loss: 0.002363330378093829\n",
      "Epoch 292/1000, Loss: 0.002363549341418966\n",
      "Epoch 293/1000, Loss: 0.0026103406904126087\n",
      "Epoch 294/1000, Loss: 0.0023562049027590452\n",
      "Epoch 295/1000, Loss: 0.0027286874542412918\n",
      "Epoch 296/1000, Loss: 0.002925166260508403\n",
      "Epoch 297/1000, Loss: 0.0023261975498657826\n",
      "Epoch 298/1000, Loss: 0.0023728055184735965\n",
      "Epoch 299/1000, Loss: 0.0032344158663383826\n",
      "Epoch 300/1000, Loss: 0.0030374390073132215\n",
      "Epoch 301/1000, Loss: 0.00266747952359576\n",
      "Epoch 302/1000, Loss: 0.0026559066581526326\n",
      "Epoch 303/1000, Loss: 0.0027171746010999677\n",
      "Epoch 304/1000, Loss: 0.002782972202960907\n",
      "Epoch 305/1000, Loss: 0.0026589885336014882\n",
      "Epoch 306/1000, Loss: 0.0025162554492927274\n",
      "Epoch 307/1000, Loss: 0.0023692127540129696\n",
      "Epoch 308/1000, Loss: 0.0031363688149648834\n",
      "Epoch 309/1000, Loss: 0.002472276259582598\n",
      "Epoch 310/1000, Loss: 0.0025707898629496314\n",
      "Epoch 311/1000, Loss: 0.0029333688583395266\n",
      "Epoch 312/1000, Loss: 0.0030644505860050303\n",
      "Epoch 313/1000, Loss: 0.00211911011515745\n",
      "Epoch 314/1000, Loss: 0.002449580295694923\n",
      "Epoch 315/1000, Loss: 0.0026479560551924456\n",
      "Epoch 316/1000, Loss: 0.002681011671242981\n",
      "Epoch 317/1000, Loss: 0.0032774786856714\n",
      "Epoch 318/1000, Loss: 0.00279105644437024\n",
      "Epoch 319/1000, Loss: 0.0027577050822322905\n",
      "Epoch 320/1000, Loss: 0.0027653760887031927\n",
      "Epoch 321/1000, Loss: 0.0031392395101607026\n",
      "Epoch 322/1000, Loss: 0.002480731787907719\n",
      "Epoch 323/1000, Loss: 0.002354797453821035\n",
      "Epoch 324/1000, Loss: 0.0025307510074872143\n",
      "Epoch 325/1000, Loss: 0.002638908865049942\n",
      "Epoch 326/1000, Loss: 0.003040279687254475\n",
      "Epoch 327/1000, Loss: 0.002477084069388698\n",
      "Epoch 328/1000, Loss: 0.0028496835006975767\n",
      "Epoch 329/1000, Loss: 0.002489822533675942\n",
      "Epoch 330/1000, Loss: 0.002896680144336067\n",
      "Epoch 331/1000, Loss: 0.00218695307994378\n",
      "Epoch 332/1000, Loss: 0.0029495182096552844\n",
      "Epoch 333/1000, Loss: 0.002856527554434196\n",
      "Epoch 334/1000, Loss: 0.0037622778999591103\n",
      "Epoch 335/1000, Loss: 0.0032873536797131866\n",
      "Epoch 336/1000, Loss: 0.0029669823381639183\n",
      "Epoch 337/1000, Loss: 0.0021063964549235324\n",
      "Epoch 338/1000, Loss: 0.0027916143359984612\n",
      "Epoch 339/1000, Loss: 0.0028393973982380125\n",
      "Epoch 340/1000, Loss: 0.003061886440014168\n",
      "Epoch 341/1000, Loss: 0.002691798451703976\n",
      "Epoch 342/1000, Loss: 0.0028154325036986337\n",
      "Epoch 343/1000, Loss: 0.0025475502802009215\n",
      "Epoch 344/1000, Loss: 0.002847541200926949\n",
      "Epoch 345/1000, Loss: 0.0024244469798791347\n",
      "Epoch 346/1000, Loss: 0.002950230770295366\n",
      "Epoch 347/1000, Loss: 0.0026538613725197633\n",
      "Epoch 348/1000, Loss: 0.002004017321481321\n",
      "Epoch 349/1000, Loss: 0.0034594865774822004\n",
      "Epoch 350/1000, Loss: 0.0021002917391758154\n",
      "Epoch 351/1000, Loss: 0.002599577268042028\n",
      "Epoch 352/1000, Loss: 0.0037917648619862354\n",
      "Epoch 353/1000, Loss: 0.002668099572707061\n",
      "Epoch 354/1000, Loss: 0.0026840612390805737\n",
      "Epoch 355/1000, Loss: 0.0028773882405016666\n",
      "Epoch 356/1000, Loss: 0.002402051184594203\n",
      "Epoch 357/1000, Loss: 0.0025503253932220686\n",
      "Epoch 358/1000, Loss: 0.0024690311811849035\n",
      "Epoch 359/1000, Loss: 0.0023524021096342075\n",
      "Epoch 360/1000, Loss: 0.003291252645481065\n",
      "Epoch 361/1000, Loss: 0.0029952478541240553\n",
      "Epoch 362/1000, Loss: 0.0023397486200122854\n",
      "Epoch 363/1000, Loss: 0.0027203928179290503\n",
      "Epoch 364/1000, Loss: 0.002907765066545823\n",
      "Epoch 365/1000, Loss: 0.0037150448330101732\n",
      "Epoch 366/1000, Loss: 0.0027266470531121913\n",
      "Epoch 367/1000, Loss: 0.0027470186019337515\n",
      "Epoch 368/1000, Loss: 0.0022128238207004616\n",
      "Epoch 369/1000, Loss: 0.0029348532980903587\n",
      "Epoch 370/1000, Loss: 0.0024940532823787822\n",
      "Epoch 371/1000, Loss: 0.002746981365895646\n",
      "Epoch 372/1000, Loss: 0.003287530542633185\n",
      "Epoch 373/1000, Loss: 0.002856471656576006\n",
      "Epoch 374/1000, Loss: 0.0025965779172483004\n",
      "Epoch 375/1000, Loss: 0.0024610678919184856\n",
      "Epoch 376/1000, Loss: 0.0027840991888151852\n",
      "Epoch 377/1000, Loss: 0.002527178700799418\n",
      "Epoch 378/1000, Loss: 0.0026552155171878995\n",
      "Epoch 379/1000, Loss: 0.0024816534576460364\n",
      "Epoch 380/1000, Loss: 0.0025997506813735687\n",
      "Epoch 381/1000, Loss: 0.002650409280790199\n",
      "Epoch 382/1000, Loss: 0.0023099042818634794\n",
      "Epoch 383/1000, Loss: 0.003449575289952639\n",
      "Epoch 384/1000, Loss: 0.0036083283843422855\n",
      "Epoch 385/1000, Loss: 0.002608576615107805\n",
      "Epoch 386/1000, Loss: 0.0018857933239149471\n",
      "Epoch 387/1000, Loss: 0.0023736958096799987\n",
      "Epoch 388/1000, Loss: 0.0024268677809214595\n",
      "Epoch 389/1000, Loss: 0.0025738617882823675\n",
      "Epoch 390/1000, Loss: 0.0023272564509234407\n",
      "Epoch 391/1000, Loss: 0.0028662211882412533\n",
      "Epoch 392/1000, Loss: 0.002925629489667403\n",
      "Epoch 393/1000, Loss: 0.0029809944281353525\n",
      "Epoch 394/1000, Loss: 0.00334488367805377\n",
      "Epoch 395/1000, Loss: 0.0026117309756048777\n",
      "Epoch 396/1000, Loss: 0.002234609842281307\n",
      "Epoch 397/1000, Loss: 0.002467330306957499\n",
      "Epoch 398/1000, Loss: 0.0022995828875690977\n",
      "Epoch 399/1000, Loss: 0.00216360118077118\n",
      "Epoch 400/1000, Loss: 0.002337676945521402\n",
      "Epoch 401/1000, Loss: 0.002517965425661746\n",
      "Epoch 402/1000, Loss: 0.0025696306951977603\n",
      "Epoch 403/1000, Loss: 0.002801924978577732\n",
      "Epoch 404/1000, Loss: 0.0027006274141950443\n",
      "Epoch 405/1000, Loss: 0.0029220330583333513\n",
      "Epoch 406/1000, Loss: 0.00345276333866812\n",
      "Epoch 407/1000, Loss: 0.002719361949346148\n",
      "Epoch 408/1000, Loss: 0.0022679184475681556\n",
      "Epoch 409/1000, Loss: 0.002896969491863832\n",
      "Epoch 410/1000, Loss: 0.002982041764215292\n",
      "Epoch 411/1000, Loss: 0.0033856713412859655\n",
      "Epoch 412/1000, Loss: 0.0032099462663458204\n",
      "Epoch 413/1000, Loss: 0.0025585464310379307\n",
      "Epoch 414/1000, Loss: 0.0027034414855641228\n",
      "Epoch 415/1000, Loss: 0.003297911695860999\n",
      "Epoch 416/1000, Loss: 0.0023702873734927185\n",
      "Epoch 417/1000, Loss: 0.0023541718028441978\n",
      "Epoch 418/1000, Loss: 0.0025477281755165414\n",
      "Epoch 419/1000, Loss: 0.0027364472996374424\n",
      "Epoch 420/1000, Loss: 0.002806081561027041\n",
      "Epoch 421/1000, Loss: 0.002662111937676794\n",
      "Epoch 422/1000, Loss: 0.0026182464451313643\n",
      "Epoch 423/1000, Loss: 0.002632562076908067\n",
      "Epoch 424/1000, Loss: 0.0027439098248985177\n",
      "Epoch 425/1000, Loss: 0.002736942041375672\n",
      "Epoch 426/1000, Loss: 0.0029823962386885637\n",
      "Epoch 427/1000, Loss: 0.002291700907198756\n",
      "Epoch 428/1000, Loss: 0.002327868660632084\n",
      "Epoch 429/1000, Loss: 0.0028670691449101046\n",
      "Epoch 430/1000, Loss: 0.0026992614825278763\n",
      "Epoch 431/1000, Loss: 0.0027672527353344847\n",
      "Epoch 432/1000, Loss: 0.00266522824917535\n",
      "Epoch 433/1000, Loss: 0.0021531949779787733\n",
      "Epoch 434/1000, Loss: 0.0028921980454516523\n",
      "Epoch 435/1000, Loss: 0.0022370680420770225\n",
      "Epoch 436/1000, Loss: 0.0024629763464213065\n",
      "Epoch 437/1000, Loss: 0.0023109347929423205\n",
      "Epoch 438/1000, Loss: 0.002518717859572372\n",
      "Epoch 439/1000, Loss: 0.002334598630474071\n",
      "Epoch 440/1000, Loss: 0.0024242354147035326\n",
      "Epoch 441/1000, Loss: 0.0029571691252894294\n",
      "Epoch 442/1000, Loss: 0.0028358958513596275\n",
      "Epoch 443/1000, Loss: 0.002759289327165437\n",
      "Epoch 444/1000, Loss: 0.002722832334745127\n",
      "Epoch 445/1000, Loss: 0.0033194738267184947\n",
      "Epoch 446/1000, Loss: 0.003036965414988033\n",
      "Epoch 447/1000, Loss: 0.003072303572451393\n",
      "Epoch 448/1000, Loss: 0.002705316011596647\n",
      "Epoch 449/1000, Loss: 0.003063710798964015\n",
      "Epoch 450/1000, Loss: 0.002915185361759538\n",
      "Epoch 451/1000, Loss: 0.0022370209893192287\n",
      "Epoch 452/1000, Loss: 0.002716229283743913\n",
      "Epoch 453/1000, Loss: 0.003584111026423063\n",
      "Epoch 454/1000, Loss: 0.0030925462612508554\n",
      "Epoch 455/1000, Loss: 0.0029690111144804287\n",
      "Epoch 456/1000, Loss: 0.0030642405241980185\n",
      "Epoch 457/1000, Loss: 0.0026866791083307\n",
      "Epoch 458/1000, Loss: 0.0027657397943036052\n",
      "Epoch 459/1000, Loss: 0.002621845191649558\n",
      "Epoch 460/1000, Loss: 0.0026872681076648163\n",
      "Epoch 461/1000, Loss: 0.002211576113377857\n",
      "Epoch 462/1000, Loss: 0.0024143263206776017\n",
      "Epoch 463/1000, Loss: 0.0027471268523409894\n",
      "Epoch 464/1000, Loss: 0.0028605002997547316\n",
      "Epoch 465/1000, Loss: 0.0029237693287462877\n",
      "Epoch 466/1000, Loss: 0.0031118096731500493\n",
      "Epoch 467/1000, Loss: 0.00348435546183959\n",
      "Epoch 468/1000, Loss: 0.0024031068911054766\n",
      "Epoch 469/1000, Loss: 0.0031860945944357424\n",
      "Epoch 470/1000, Loss: 0.0026749276620977092\n",
      "Epoch 471/1000, Loss: 0.0021556946415100904\n",
      "Epoch 472/1000, Loss: 0.0025173739682162496\n",
      "Epoch 473/1000, Loss: 0.0030478086233886254\n",
      "Epoch 474/1000, Loss: 0.0025649484172152385\n",
      "Epoch 475/1000, Loss: 0.0027173969762622676\n",
      "Epoch 476/1000, Loss: 0.0025212191851369716\n",
      "Epoch 477/1000, Loss: 0.002847629206609764\n",
      "Epoch 478/1000, Loss: 0.002934244650387205\n",
      "Epoch 479/1000, Loss: 0.0028874487197114943\n",
      "Epoch 480/1000, Loss: 0.0024379888084785344\n",
      "Epoch 481/1000, Loss: 0.0026729827455687374\n",
      "Epoch 482/1000, Loss: 0.0029451728006299493\n",
      "Epoch 483/1000, Loss: 0.0034058197911559754\n",
      "Epoch 484/1000, Loss: 0.0020549874966447603\n",
      "Epoch 485/1000, Loss: 0.002934202988463119\n",
      "Epoch 486/1000, Loss: 0.002552166653837897\n",
      "Epoch 487/1000, Loss: 0.0025222092398342185\n",
      "Epoch 488/1000, Loss: 0.0027328462557065746\n",
      "Epoch 489/1000, Loss: 0.0027052521475760647\n",
      "Epoch 490/1000, Loss: 0.002246036720714129\n",
      "Epoch 491/1000, Loss: 0.002969996837559513\n",
      "Epoch 492/1000, Loss: 0.0028461536928840164\n",
      "Epoch 493/1000, Loss: 0.002811460260820165\n",
      "Epoch 494/1000, Loss: 0.0025971712861436523\n",
      "Epoch 495/1000, Loss: 0.0019243286032652365\n",
      "Epoch 496/1000, Loss: 0.0028824707020225506\n",
      "Epoch 497/1000, Loss: 0.002625692609442852\n",
      "Epoch 498/1000, Loss: 0.002877462888002842\n",
      "Epoch 499/1000, Loss: 0.002730336203944208\n",
      "Epoch 500/1000, Loss: 0.002273952714094543\n",
      "Epoch 501/1000, Loss: 0.0026800253548420975\n",
      "Epoch 502/1000, Loss: 0.0024234171847905537\n",
      "Epoch 503/1000, Loss: 0.0023469278915402535\n",
      "Epoch 504/1000, Loss: 0.002516511572525742\n",
      "Epoch 505/1000, Loss: 0.003271972821444876\n",
      "Epoch 506/1000, Loss: 0.003264198021997364\n",
      "Epoch 507/1000, Loss: 0.0022965155395343224\n",
      "Epoch 508/1000, Loss: 0.003009608386241998\n",
      "Epoch 509/1000, Loss: 0.002445892372303008\n",
      "Epoch 510/1000, Loss: 0.0032721429756762494\n",
      "Epoch 511/1000, Loss: 0.0025003533953455457\n",
      "Epoch 512/1000, Loss: 0.00249237430923128\n",
      "Epoch 513/1000, Loss: 0.0021574634575429515\n",
      "Epoch 514/1000, Loss: 0.0027089450085536946\n",
      "Epoch 515/1000, Loss: 0.003177483734486832\n",
      "Epoch 516/1000, Loss: 0.0024506785158531835\n",
      "Epoch 517/1000, Loss: 0.002249919295272107\n",
      "Epoch 518/1000, Loss: 0.0023896698435600557\n",
      "Epoch 519/1000, Loss: 0.0028026369974321107\n",
      "Epoch 520/1000, Loss: 0.0026765838635667617\n",
      "Epoch 521/1000, Loss: 0.0024647694046141116\n",
      "Epoch 522/1000, Loss: 0.003132610041552144\n",
      "Epoch 523/1000, Loss: 0.002514514310473787\n",
      "Epoch 524/1000, Loss: 0.0029793269186949313\n",
      "Epoch 525/1000, Loss: 0.002977549244410322\n",
      "Epoch 526/1000, Loss: 0.002645469546423962\n",
      "Epoch 527/1000, Loss: 0.0023729185326455495\n",
      "Epoch 528/1000, Loss: 0.0034135646904566636\n",
      "Epoch 529/1000, Loss: 0.002514110661313128\n",
      "Epoch 530/1000, Loss: 0.0032066721436561562\n",
      "Epoch 531/1000, Loss: 0.003406445427941208\n",
      "Epoch 532/1000, Loss: 0.002714577571953323\n",
      "Epoch 533/1000, Loss: 0.0035979160884758435\n",
      "Epoch 534/1000, Loss: 0.0032346755164000727\n",
      "Epoch 535/1000, Loss: 0.003266492993401634\n",
      "Epoch 536/1000, Loss: 0.0022368332482614506\n",
      "Epoch 537/1000, Loss: 0.0024345717527571665\n",
      "Epoch 538/1000, Loss: 0.003322020486020353\n",
      "Epoch 539/1000, Loss: 0.0019505309381132358\n",
      "Epoch 540/1000, Loss: 0.00278517675660943\n",
      "Epoch 541/1000, Loss: 0.0030911775223832517\n",
      "Epoch 542/1000, Loss: 0.0031405032477545692\n",
      "Epoch 543/1000, Loss: 0.002426406165665167\n",
      "Epoch 544/1000, Loss: 0.002308849928488543\n",
      "Epoch 545/1000, Loss: 0.002714959511190689\n",
      "Epoch 546/1000, Loss: 0.003170884490357301\n",
      "Epoch 547/1000, Loss: 0.0023685348814601334\n",
      "Epoch 548/1000, Loss: 0.002826734200594095\n",
      "Epoch 549/1000, Loss: 0.0026134398672924995\n",
      "Epoch 550/1000, Loss: 0.0026949067949189544\n",
      "Epoch 551/1000, Loss: 0.0032070469197946114\n",
      "Epoch 552/1000, Loss: 0.002657002837137455\n",
      "Epoch 553/1000, Loss: 0.00281154014767333\n",
      "Epoch 554/1000, Loss: 0.002875967968693745\n",
      "Epoch 555/1000, Loss: 0.0024114702513944298\n",
      "Epoch 556/1000, Loss: 0.0025222700099920958\n",
      "Epoch 557/1000, Loss: 0.002219566540245981\n",
      "Epoch 558/1000, Loss: 0.0027957765652766317\n",
      "Epoch 559/1000, Loss: 0.0028264804217478477\n",
      "Epoch 560/1000, Loss: 0.002700199864228433\n",
      "Epoch 561/1000, Loss: 0.0023532734040126553\n",
      "Epoch 562/1000, Loss: 0.0018139056857134988\n",
      "Epoch 563/1000, Loss: 0.0031591629579048376\n",
      "Epoch 564/1000, Loss: 0.002209583647129239\n",
      "Epoch 565/1000, Loss: 0.002761564029053563\n",
      "Epoch 566/1000, Loss: 0.0030195917949231007\n",
      "Epoch 567/1000, Loss: 0.0026834042736548764\n",
      "Epoch 568/1000, Loss: 0.0024408407539441962\n",
      "Epoch 569/1000, Loss: 0.002954920240928112\n",
      "Epoch 570/1000, Loss: 0.0020890843950099676\n",
      "Epoch 571/1000, Loss: 0.0023335135050229364\n",
      "Epoch 572/1000, Loss: 0.0029549141951303666\n",
      "Epoch 573/1000, Loss: 0.0019218338734085171\n",
      "Epoch 574/1000, Loss: 0.002754900075346516\n",
      "Epoch 575/1000, Loss: 0.003092446465151866\n",
      "Epoch 576/1000, Loss: 0.0031736385065998705\n",
      "Epoch 577/1000, Loss: 0.0032476945770686843\n",
      "Epoch 578/1000, Loss: 0.0026103812491573963\n",
      "Epoch 579/1000, Loss: 0.003102749278876293\n",
      "Epoch 580/1000, Loss: 0.00245306925902545\n",
      "Epoch 581/1000, Loss: 0.0025003612845873506\n",
      "Epoch 582/1000, Loss: 0.003005523827520786\n",
      "Epoch 583/1000, Loss: 0.002850619400262146\n",
      "Epoch 584/1000, Loss: 0.0026941776015734307\n",
      "Epoch 585/1000, Loss: 0.002499709857135913\n",
      "Epoch 586/1000, Loss: 0.0029184046712433516\n",
      "Epoch 587/1000, Loss: 0.002380240962887759\n",
      "Epoch 588/1000, Loss: 0.0030307235944366283\n",
      "Epoch 589/1000, Loss: 0.0032999198558968964\n",
      "Epoch 590/1000, Loss: 0.0021610019365254905\n",
      "Epoch 591/1000, Loss: 0.003462103389475246\n",
      "Epoch 592/1000, Loss: 0.0023597417944670224\n",
      "Epoch 593/1000, Loss: 0.0028267088912220257\n",
      "Epoch 594/1000, Loss: 0.0022775986358878936\n",
      "Epoch 595/1000, Loss: 0.0027685689529635665\n",
      "Epoch 596/1000, Loss: 0.0022911134262558744\n",
      "Epoch 597/1000, Loss: 0.00320029385904444\n",
      "Epoch 598/1000, Loss: 0.0023067460454079956\n",
      "Epoch 599/1000, Loss: 0.0025745686075816874\n",
      "Epoch 600/1000, Loss: 0.0024826988612095505\n",
      "Epoch 601/1000, Loss: 0.0028222060980729125\n",
      "Epoch 602/1000, Loss: 0.0027536967058383196\n",
      "Epoch 603/1000, Loss: 0.002542250900073334\n",
      "Epoch 604/1000, Loss: 0.0024076394923187075\n",
      "Epoch 605/1000, Loss: 0.0023686018793321307\n",
      "Epoch 606/1000, Loss: 0.003033373408023169\n",
      "Epoch 607/1000, Loss: 0.0026581830192554797\n",
      "Epoch 608/1000, Loss: 0.003379607105775918\n",
      "Epoch 609/1000, Loss: 0.0029034804702066865\n",
      "Epoch 610/1000, Loss: 0.002716730116748812\n",
      "Epoch 611/1000, Loss: 0.0033473076749500593\n",
      "Epoch 612/1000, Loss: 0.00251854611756665\n",
      "Epoch 613/1000, Loss: 0.003606752938465277\n",
      "Epoch 614/1000, Loss: 0.0025253062777801606\n",
      "Epoch 615/1000, Loss: 0.0024763974228968876\n",
      "Epoch 616/1000, Loss: 0.002924380135084266\n",
      "Epoch 617/1000, Loss: 0.0024909932440197575\n",
      "Epoch 618/1000, Loss: 0.0028812969313946903\n",
      "Epoch 619/1000, Loss: 0.002990342082364677\n",
      "Epoch 620/1000, Loss: 0.0025328588334219784\n",
      "Epoch 621/1000, Loss: 0.002510270990677064\n",
      "Epoch 622/1000, Loss: 0.002477669210117446\n",
      "Epoch 623/1000, Loss: 0.0025342039907714792\n",
      "Epoch 624/1000, Loss: 0.003035820521072659\n",
      "Epoch 625/1000, Loss: 0.002290669478750674\n",
      "Epoch 626/1000, Loss: 0.002489790465967879\n",
      "Epoch 627/1000, Loss: 0.002847949246335103\n",
      "Epoch 628/1000, Loss: 0.0029121652717610316\n",
      "Epoch 629/1000, Loss: 0.0036445126222537593\n",
      "Epoch 630/1000, Loss: 0.002973429774830872\n",
      "Epoch 631/1000, Loss: 0.002676786846070416\n",
      "Epoch 632/1000, Loss: 0.002615786946658575\n",
      "Epoch 633/1000, Loss: 0.002170754052463271\n",
      "Epoch 634/1000, Loss: 0.002807401093197693\n",
      "Epoch 635/1000, Loss: 0.002103742387656423\n",
      "Epoch 636/1000, Loss: 0.0026638953674821457\n",
      "Epoch 637/1000, Loss: 0.0023958367487655475\n",
      "Epoch 638/1000, Loss: 0.0032786361174681187\n",
      "Epoch 639/1000, Loss: 0.002443445772964021\n",
      "Epoch 640/1000, Loss: 0.0024515569100785274\n",
      "Epoch 641/1000, Loss: 0.0029049953660467815\n",
      "Epoch 642/1000, Loss: 0.0024074351554873646\n",
      "Epoch 643/1000, Loss: 0.002194634573173355\n",
      "Epoch 644/1000, Loss: 0.0026404303215315215\n",
      "Epoch 645/1000, Loss: 0.0027360849447790425\n",
      "Epoch 646/1000, Loss: 0.0023603574822751838\n",
      "Epoch 647/1000, Loss: 0.0024002645714934685\n",
      "Epoch 648/1000, Loss: 0.0031057666498285176\n",
      "Epoch 649/1000, Loss: 0.002532705012239336\n",
      "Epoch 650/1000, Loss: 0.0031930964026493564\n",
      "Epoch 651/1000, Loss: 0.0028854958175168447\n",
      "Epoch 652/1000, Loss: 0.0032506716336425283\n",
      "Epoch 653/1000, Loss: 0.0025542463705807194\n",
      "Epoch 654/1000, Loss: 0.0028082125163535285\n",
      "Epoch 655/1000, Loss: 0.0031062782020507993\n",
      "Epoch 656/1000, Loss: 0.002426704145593609\n",
      "Epoch 657/1000, Loss: 0.002724365543194211\n",
      "Epoch 658/1000, Loss: 0.0026666586958985854\n",
      "Epoch 659/1000, Loss: 0.0026414702494894473\n",
      "Epoch 660/1000, Loss: 0.0027936279399848815\n",
      "Epoch 661/1000, Loss: 0.0029636294012727474\n",
      "Epoch 662/1000, Loss: 0.002435558807342306\n",
      "Epoch 663/1000, Loss: 0.0030506670643317834\n",
      "Epoch 664/1000, Loss: 0.0032082456801463804\n",
      "Epoch 665/1000, Loss: 0.0027884414264412126\n",
      "Epoch 666/1000, Loss: 0.0026205499998526553\n",
      "Epoch 667/1000, Loss: 0.002249259089389431\n",
      "Epoch 668/1000, Loss: 0.0024976026957599204\n",
      "Epoch 669/1000, Loss: 0.0026196562646716736\n",
      "Epoch 670/1000, Loss: 0.002627447924651598\n",
      "Epoch 671/1000, Loss: 0.002708103055665677\n",
      "Epoch 672/1000, Loss: 0.0028678489685878337\n",
      "Epoch 673/1000, Loss: 0.0024236303101709007\n",
      "Epoch 674/1000, Loss: 0.0030585698249068084\n",
      "Epoch 675/1000, Loss: 0.0025354391253206874\n",
      "Epoch 676/1000, Loss: 0.002494910993183626\n",
      "Epoch 677/1000, Loss: 0.0029225579375471247\n",
      "Epoch 678/1000, Loss: 0.002858272057285165\n",
      "Epoch 679/1000, Loss: 0.002679088085235631\n",
      "Epoch 680/1000, Loss: 0.0028113852971925783\n",
      "Epoch 681/1000, Loss: 0.0024899065388722147\n",
      "Epoch 682/1000, Loss: 0.0024831437704661698\n",
      "Epoch 683/1000, Loss: 0.0022503129469589964\n",
      "Epoch 684/1000, Loss: 0.0021932397541470925\n",
      "Epoch 685/1000, Loss: 0.003048528381711662\n",
      "Epoch 686/1000, Loss: 0.0032079910544472426\n",
      "Epoch 687/1000, Loss: 0.0031996998191105306\n",
      "Epoch 688/1000, Loss: 0.0026649684729002036\n",
      "Epoch 689/1000, Loss: 0.003057202746637055\n",
      "Epoch 690/1000, Loss: 0.0024333474514289044\n",
      "Epoch 691/1000, Loss: 0.0019355249917160213\n",
      "Epoch 692/1000, Loss: 0.0026435514754355742\n",
      "Epoch 693/1000, Loss: 0.002581854272921482\n",
      "Epoch 694/1000, Loss: 0.002029539421478773\n",
      "Epoch 695/1000, Loss: 0.003001662574825342\n",
      "Epoch 696/1000, Loss: 0.0026897330197232098\n",
      "Epoch 697/1000, Loss: 0.002660735702782915\n",
      "Epoch 698/1000, Loss: 0.002943032174085491\n",
      "Epoch 699/1000, Loss: 0.002601164398938432\n",
      "Epoch 700/1000, Loss: 0.0027101266099076914\n",
      "Epoch 701/1000, Loss: 0.002153582800414829\n",
      "Epoch 702/1000, Loss: 0.002090050069594649\n",
      "Epoch 703/1000, Loss: 0.002655768597182346\n",
      "Epoch 704/1000, Loss: 0.0023163076123959973\n",
      "Epoch 705/1000, Loss: 0.002812832288635635\n",
      "Epoch 706/1000, Loss: 0.0030024691055854356\n",
      "Epoch 707/1000, Loss: 0.002452300842369746\n",
      "Epoch 708/1000, Loss: 0.0027070152358553753\n",
      "Epoch 709/1000, Loss: 0.0024336158815548552\n",
      "Epoch 710/1000, Loss: 0.0030924858342833944\n",
      "Epoch 711/1000, Loss: 0.002133421616264922\n",
      "Epoch 712/1000, Loss: 0.0029536291558513814\n",
      "Epoch 713/1000, Loss: 0.00339653937502729\n",
      "Epoch 714/1000, Loss: 0.002171951072094484\n",
      "Epoch 715/1000, Loss: 0.0034012751101677795\n",
      "Epoch 716/1000, Loss: 0.0028848241888049515\n",
      "Epoch 717/1000, Loss: 0.0026098727080018386\n",
      "Epoch 718/1000, Loss: 0.002902665178333528\n",
      "Epoch 719/1000, Loss: 0.003124562218484159\n",
      "Epoch 720/1000, Loss: 0.002751035615650713\n",
      "Epoch 721/1000, Loss: 0.002884206861035462\n",
      "Epoch 722/1000, Loss: 0.0028649192171231468\n",
      "Epoch 723/1000, Loss: 0.0023490749829357727\n",
      "Epoch 724/1000, Loss: 0.0025801003591539935\n",
      "Epoch 725/1000, Loss: 0.0027173878479109332\n",
      "Epoch 726/1000, Loss: 0.0030532428819291736\n",
      "Epoch 727/1000, Loss: 0.0020680670538789706\n",
      "Epoch 728/1000, Loss: 0.002499001194421591\n",
      "Epoch 729/1000, Loss: 0.002274590559105613\n",
      "Epoch 730/1000, Loss: 0.002252366366943946\n",
      "Epoch 731/1000, Loss: 0.0029292437464932164\n",
      "Epoch 732/1000, Loss: 0.002426042664982918\n",
      "Epoch 733/1000, Loss: 0.002680269059665922\n",
      "Epoch 734/1000, Loss: 0.0020550741480870587\n",
      "Epoch 735/1000, Loss: 0.0020905947579168463\n",
      "Epoch 736/1000, Loss: 0.0025654134686180644\n",
      "Epoch 737/1000, Loss: 0.002558265898913962\n",
      "Epoch 738/1000, Loss: 0.003021744917750417\n",
      "Epoch 739/1000, Loss: 0.0021055276291694095\n",
      "Epoch 740/1000, Loss: 0.0024277392053082525\n",
      "Epoch 741/1000, Loss: 0.0023427450637471267\n",
      "Epoch 742/1000, Loss: 0.0028954782316756612\n",
      "Epoch 743/1000, Loss: 0.0026718417783575107\n",
      "Epoch 744/1000, Loss: 0.0027541109786060943\n",
      "Epoch 745/1000, Loss: 0.002617314145718759\n",
      "Epoch 746/1000, Loss: 0.00205303834084766\n",
      "Epoch 747/1000, Loss: 0.003076719250153189\n",
      "Epoch 748/1000, Loss: 0.0032555883446007783\n",
      "Epoch 749/1000, Loss: 0.0026571708995135803\n",
      "Epoch 750/1000, Loss: 0.003279707288934318\n",
      "Epoch 751/1000, Loss: 0.0023071401219248\n",
      "Epoch 752/1000, Loss: 0.003177723758547824\n",
      "Epoch 753/1000, Loss: 0.002558381903905486\n",
      "Epoch 754/1000, Loss: 0.0024524440465877803\n",
      "Epoch 755/1000, Loss: 0.002075344985811467\n",
      "Epoch 756/1000, Loss: 0.003270714309929607\n",
      "Epoch 757/1000, Loss: 0.0022709910298756974\n",
      "Epoch 758/1000, Loss: 0.0027816926060924055\n",
      "Epoch 759/1000, Loss: 0.0025364644141971805\n",
      "Epoch 760/1000, Loss: 0.0026366453257186382\n",
      "Epoch 761/1000, Loss: 0.0028023081726562707\n",
      "Epoch 762/1000, Loss: 0.002203471319404843\n",
      "Epoch 763/1000, Loss: 0.0022519025824120314\n",
      "Epoch 764/1000, Loss: 0.0027750854708497768\n",
      "Epoch 765/1000, Loss: 0.0025472555236611774\n",
      "Epoch 766/1000, Loss: 0.002686174330768825\n",
      "Epoch 767/1000, Loss: 0.0028865921555150478\n",
      "Epoch 768/1000, Loss: 0.0022994077747319295\n",
      "Epoch 769/1000, Loss: 0.0025088087409290637\n",
      "Epoch 770/1000, Loss: 0.0027704849634960665\n",
      "Epoch 771/1000, Loss: 0.0028429799055859255\n",
      "Epoch 772/1000, Loss: 0.0026128772134570363\n",
      "Epoch 773/1000, Loss: 0.0031034872802101804\n",
      "Epoch 774/1000, Loss: 0.0023076997459166872\n",
      "Epoch 775/1000, Loss: 0.003204671612409514\n",
      "Epoch 776/1000, Loss: 0.002442580594132554\n",
      "Epoch 777/1000, Loss: 0.002448994095983088\n",
      "Epoch 778/1000, Loss: 0.002820585280841015\n",
      "Epoch 779/1000, Loss: 0.0026031330346301205\n",
      "Epoch 780/1000, Loss: 0.0021058978943187504\n",
      "Epoch 781/1000, Loss: 0.002827203302014602\n",
      "Epoch 782/1000, Loss: 0.0033735530327213986\n",
      "Epoch 783/1000, Loss: 0.002806157442384179\n",
      "Epoch 784/1000, Loss: 0.003090915311649399\n",
      "Epoch 785/1000, Loss: 0.002814988381861024\n",
      "Epoch 786/1000, Loss: 0.003173718766002987\n",
      "Epoch 787/1000, Loss: 0.002697264270193028\n",
      "Epoch 788/1000, Loss: 0.0029914458608082772\n",
      "Epoch 789/1000, Loss: 0.0024309835400763463\n",
      "Epoch 790/1000, Loss: 0.0026752747049706375\n",
      "Epoch 791/1000, Loss: 0.0024254449819909787\n",
      "Epoch 792/1000, Loss: 0.002689566152120926\n",
      "Epoch 793/1000, Loss: 0.002944951189495502\n",
      "Epoch 794/1000, Loss: 0.0030703987957591793\n",
      "Epoch 795/1000, Loss: 0.0025564352301862586\n",
      "Epoch 796/1000, Loss: 0.0025698941476969828\n",
      "Epoch 797/1000, Loss: 0.0024895003549701617\n",
      "Epoch 798/1000, Loss: 0.00275522351638445\n",
      "Epoch 799/1000, Loss: 0.0027018507244472205\n",
      "Epoch 800/1000, Loss: 0.0027607724047837797\n",
      "Epoch 801/1000, Loss: 0.0029597072443953575\n",
      "Epoch 802/1000, Loss: 0.00264495339516883\n",
      "Epoch 803/1000, Loss: 0.0031523904853239886\n",
      "Epoch 804/1000, Loss: 0.002579958834089826\n",
      "Epoch 805/1000, Loss: 0.0025090199940579054\n",
      "Epoch 806/1000, Loss: 0.0026940319417197013\n",
      "Epoch 807/1000, Loss: 0.0024559470043917387\n",
      "Epoch 808/1000, Loss: 0.0031541323167071627\n",
      "Epoch 809/1000, Loss: 0.002771354716336204\n",
      "Epoch 810/1000, Loss: 0.0031045225401647564\n",
      "Epoch 811/1000, Loss: 0.0031548931915945295\n",
      "Epoch 812/1000, Loss: 0.002481760720487315\n",
      "Epoch 813/1000, Loss: 0.0026059443710817988\n",
      "Epoch 814/1000, Loss: 0.0030791916224508385\n",
      "Epoch 815/1000, Loss: 0.0022639579095610567\n",
      "Epoch 816/1000, Loss: 0.0025067137374225395\n",
      "Epoch 817/1000, Loss: 0.0020479542388424157\n",
      "Epoch 818/1000, Loss: 0.0033985365120920083\n",
      "Epoch 819/1000, Loss: 0.002717472600822269\n",
      "Epoch 820/1000, Loss: 0.002268140013936867\n",
      "Epoch 821/1000, Loss: 0.0023698907962955325\n",
      "Epoch 822/1000, Loss: 0.003306929944917389\n",
      "Epoch 823/1000, Loss: 0.0026812214022670605\n",
      "Epoch 824/1000, Loss: 0.003308159479588583\n",
      "Epoch 825/1000, Loss: 0.003224388022401992\n",
      "Epoch 826/1000, Loss: 0.0026345255161363975\n",
      "Epoch 827/1000, Loss: 0.002176763399601944\n",
      "Epoch 828/1000, Loss: 0.0027118747742041743\n",
      "Epoch 829/1000, Loss: 0.003565151998248093\n",
      "Epoch 830/1000, Loss: 0.002214831640021628\n",
      "Epoch 831/1000, Loss: 0.002797583941664867\n",
      "Epoch 832/1000, Loss: 0.00266063593580519\n",
      "Epoch 833/1000, Loss: 0.0031581690092684985\n",
      "Epoch 834/1000, Loss: 0.002315544559434447\n",
      "Epoch 835/1000, Loss: 0.0028231764090814277\n",
      "Epoch 836/1000, Loss: 0.0023897809077986143\n",
      "Epoch 837/1000, Loss: 0.0030018031349882744\n",
      "Epoch 838/1000, Loss: 0.00328396861393082\n",
      "Epoch 839/1000, Loss: 0.0028363110320588194\n",
      "Epoch 840/1000, Loss: 0.0028403867909451573\n",
      "Epoch 841/1000, Loss: 0.002960724179211421\n",
      "Epoch 842/1000, Loss: 0.0027783195441814243\n",
      "Epoch 843/1000, Loss: 0.0028273772427717097\n",
      "Epoch 844/1000, Loss: 0.0028162742186593507\n",
      "Epoch 845/1000, Loss: 0.002812247093651024\n",
      "Epoch 846/1000, Loss: 0.00265504064531743\n",
      "Epoch 847/1000, Loss: 0.0031228380979615457\n",
      "Epoch 848/1000, Loss: 0.00314917532533275\n",
      "Epoch 849/1000, Loss: 0.0032042992790808442\n",
      "Epoch 850/1000, Loss: 0.003104943465470755\n",
      "Epoch 851/1000, Loss: 0.0026857570375197477\n",
      "Epoch 852/1000, Loss: 0.002536502440374063\n",
      "Epoch 853/1000, Loss: 0.0028336486451990958\n",
      "Epoch 854/1000, Loss: 0.0028695080300545064\n",
      "Epoch 855/1000, Loss: 0.002280004091482316\n",
      "Epoch 856/1000, Loss: 0.002686653596614947\n",
      "Epoch 857/1000, Loss: 0.0023854560707298276\n",
      "Epoch 858/1000, Loss: 0.002878312929739148\n",
      "Epoch 859/1000, Loss: 0.0024008483887882903\n",
      "Epoch 860/1000, Loss: 0.0022596006773196228\n",
      "Epoch 861/1000, Loss: 0.0021968739426626188\n",
      "Epoch 862/1000, Loss: 0.00285977970014619\n",
      "Epoch 863/1000, Loss: 0.002435019934061904\n",
      "Epoch 864/1000, Loss: 0.003225669371346657\n",
      "Epoch 865/1000, Loss: 0.0024887393918066\n",
      "Epoch 866/1000, Loss: 0.002648486948723244\n",
      "Epoch 867/1000, Loss: 0.0034366252739026605\n",
      "Epoch 868/1000, Loss: 0.0028800479117322515\n",
      "Epoch 869/1000, Loss: 0.0026561960216038194\n",
      "Epoch 870/1000, Loss: 0.0031147181708103\n",
      "Epoch 871/1000, Loss: 0.002153557301728386\n",
      "Epoch 872/1000, Loss: 0.0027485868389988443\n",
      "Epoch 873/1000, Loss: 0.002824535943775478\n",
      "Epoch 874/1000, Loss: 0.0026526641150600443\n",
      "Epoch 875/1000, Loss: 0.0025069581872881512\n",
      "Epoch 876/1000, Loss: 0.002703425218045502\n",
      "Epoch 877/1000, Loss: 0.00256756881143187\n",
      "Epoch 878/1000, Loss: 0.0026295557311993055\n",
      "Epoch 879/1000, Loss: 0.0021711580119795535\n",
      "Epoch 880/1000, Loss: 0.0030543056787623478\n",
      "Epoch 881/1000, Loss: 0.003150870303367023\n",
      "Epoch 882/1000, Loss: 0.002373650107600292\n",
      "Epoch 883/1000, Loss: 0.0027233126905494586\n",
      "Epoch 884/1000, Loss: 0.003052344938757383\n",
      "Epoch 885/1000, Loss: 0.0029532067708674067\n",
      "Epoch 886/1000, Loss: 0.002783837490431952\n",
      "Epoch 887/1000, Loss: 0.0022773462410659354\n",
      "Epoch 888/1000, Loss: 0.0024254236796549754\n",
      "Epoch 889/1000, Loss: 0.002818415019629202\n",
      "Epoch 890/1000, Loss: 0.002797210920281662\n",
      "Epoch 891/1000, Loss: 0.002488902829620097\n",
      "Epoch 892/1000, Loss: 0.002863400460405399\n",
      "Epoch 893/1000, Loss: 0.0025550516014607653\n",
      "Epoch 894/1000, Loss: 0.002704460198445234\n",
      "Epoch 895/1000, Loss: 0.001960576492689352\n",
      "Epoch 896/1000, Loss: 0.002095608111078919\n",
      "Epoch 897/1000, Loss: 0.0026011217298753633\n",
      "Epoch 898/1000, Loss: 0.003126213798918144\n",
      "Epoch 899/1000, Loss: 0.0027204779096373327\n",
      "Epoch 900/1000, Loss: 0.002381263354457009\n",
      "Epoch 901/1000, Loss: 0.0026697905594252882\n",
      "Epoch 902/1000, Loss: 0.0033322386053200558\n",
      "Epoch 903/1000, Loss: 0.002951196448669124\n",
      "Epoch 904/1000, Loss: 0.002477932003834497\n",
      "Epoch 905/1000, Loss: 0.0025454841815750672\n",
      "Epoch 906/1000, Loss: 0.0029644822195481852\n",
      "Epoch 907/1000, Loss: 0.0031165547082603264\n",
      "Epoch 908/1000, Loss: 0.0021863860991277054\n",
      "Epoch 909/1000, Loss: 0.002573858658196784\n",
      "Epoch 910/1000, Loss: 0.002440133933401222\n",
      "Epoch 911/1000, Loss: 0.0033641057404591953\n",
      "Epoch 912/1000, Loss: 0.0026390593204164347\n",
      "Epoch 913/1000, Loss: 0.002485816611784429\n",
      "Epoch 914/1000, Loss: 0.0027130368921418338\n",
      "Epoch 915/1000, Loss: 0.0026484622671466007\n",
      "Epoch 916/1000, Loss: 0.0029396958786227756\n",
      "Epoch 917/1000, Loss: 0.0023149617127360984\n",
      "Epoch 918/1000, Loss: 0.00320242634368191\n",
      "Epoch 919/1000, Loss: 0.002661340232247568\n",
      "Epoch 920/1000, Loss: 0.002533817062063614\n",
      "Epoch 921/1000, Loss: 0.002208914822624876\n",
      "Epoch 922/1000, Loss: 0.002943056099950492\n",
      "Epoch 923/1000, Loss: 0.0029322258381169015\n",
      "Epoch 924/1000, Loss: 0.002964635385790036\n",
      "Epoch 925/1000, Loss: 0.0027193829545766744\n",
      "Epoch 926/1000, Loss: 0.0025469107917300204\n",
      "Epoch 927/1000, Loss: 0.0023742116286760862\n",
      "Epoch 928/1000, Loss: 0.0033413886931999985\n",
      "Epoch 929/1000, Loss: 0.0025365413237424376\n",
      "Epoch 930/1000, Loss: 0.002778481736562515\n",
      "Epoch 931/1000, Loss: 0.002814835123768926\n",
      "Epoch 932/1000, Loss: 0.002323746073880131\n",
      "Epoch 933/1000, Loss: 0.00299897446162655\n",
      "Epoch 934/1000, Loss: 0.002548858062153321\n",
      "Epoch 935/1000, Loss: 0.0027299823640890256\n",
      "Epoch 936/1000, Loss: 0.0025547097337986573\n",
      "Epoch 937/1000, Loss: 0.003205246429402882\n",
      "Epoch 938/1000, Loss: 0.0025031356236081665\n",
      "Epoch 939/1000, Loss: 0.002715106197628572\n",
      "Epoch 940/1000, Loss: 0.0024181771956839986\n",
      "Epoch 941/1000, Loss: 0.0031547866170169984\n",
      "Epoch 942/1000, Loss: 0.0024443250298668826\n",
      "Epoch 943/1000, Loss: 0.0027541661659542384\n",
      "Epoch 944/1000, Loss: 0.0026624117641642427\n",
      "Epoch 945/1000, Loss: 0.0035010359164626974\n",
      "Epoch 946/1000, Loss: 0.0023747174599500465\n",
      "Epoch 947/1000, Loss: 0.0027494105372414535\n",
      "Epoch 948/1000, Loss: 0.0027244173380864367\n",
      "Epoch 949/1000, Loss: 0.0023187120516170146\n",
      "Epoch 950/1000, Loss: 0.0029999766827245003\n",
      "Epoch 951/1000, Loss: 0.002855468563025649\n",
      "Epoch 952/1000, Loss: 0.0024607942342610707\n",
      "Epoch 953/1000, Loss: 0.002275539829038469\n",
      "Epoch 954/1000, Loss: 0.002926850899441775\n",
      "Epoch 955/1000, Loss: 0.002469454437249778\n",
      "Epoch 956/1000, Loss: 0.0025142606677495487\n",
      "Epoch 957/1000, Loss: 0.0028052099193320345\n",
      "Epoch 958/1000, Loss: 0.0025594637873131106\n",
      "Epoch 959/1000, Loss: 0.0025154683697766853\n",
      "Epoch 960/1000, Loss: 0.0027517250376646483\n",
      "Epoch 961/1000, Loss: 0.00297643644666758\n",
      "Epoch 962/1000, Loss: 0.003051585331990392\n",
      "Epoch 963/1000, Loss: 0.002592867002922881\n",
      "Epoch 964/1000, Loss: 0.002195827022631466\n",
      "Epoch 965/1000, Loss: 0.002789090309138097\n",
      "Epoch 966/1000, Loss: 0.002859413462297503\n",
      "Epoch 967/1000, Loss: 0.002347348224849467\n",
      "Epoch 968/1000, Loss: 0.0032835183849902923\n",
      "Epoch 969/1000, Loss: 0.00234431047653188\n",
      "Epoch 970/1000, Loss: 0.0024272536965045306\n",
      "Epoch 971/1000, Loss: 0.003099069146018404\n",
      "Epoch 972/1000, Loss: 0.00261452441452584\n",
      "Epoch 973/1000, Loss: 0.0032265450984569947\n",
      "Epoch 974/1000, Loss: 0.002751463184074546\n",
      "Epoch 975/1000, Loss: 0.0031394534245291566\n",
      "Epoch 976/1000, Loss: 0.0028222963233877174\n",
      "Epoch 977/1000, Loss: 0.003082842423575752\n",
      "Epoch 978/1000, Loss: 0.002575351296115424\n",
      "Epoch 979/1000, Loss: 0.00277182598488209\n",
      "Epoch 980/1000, Loss: 0.0024902181353892096\n",
      "Epoch 981/1000, Loss: 0.0025540017386302\n",
      "Epoch 982/1000, Loss: 0.0031014996902885964\n",
      "Epoch 983/1000, Loss: 0.002034906368252517\n",
      "Epoch 984/1000, Loss: 0.002964791495470561\n",
      "Epoch 985/1000, Loss: 0.0024066079888968805\n",
      "Epoch 986/1000, Loss: 0.0027058001954845183\n",
      "Epoch 987/1000, Loss: 0.0025647831691644088\n",
      "Epoch 988/1000, Loss: 0.002665740219474621\n",
      "Epoch 989/1000, Loss: 0.002351835664850483\n",
      "Epoch 990/1000, Loss: 0.002555407658762826\n",
      "Epoch 991/1000, Loss: 0.0032591444626199483\n",
      "Epoch 992/1000, Loss: 0.002705700883922463\n",
      "Epoch 993/1000, Loss: 0.002624978341073917\n",
      "Epoch 994/1000, Loss: 0.002597727332712226\n",
      "Epoch 995/1000, Loss: 0.002817461551503671\n",
      "Epoch 996/1000, Loss: 0.0024605152204469757\n",
      "Epoch 997/1000, Loss: 0.002345228897805016\n",
      "Epoch 998/1000, Loss: 0.0022701564280991943\n",
      "Epoch 999/1000, Loss: 0.0032955579005477754\n",
      "Epoch 1000/1000, Loss: 0.0024324860668233665\n",
      "Test Accuracy: 99.92%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "\n",
    "# Define the Transformer model for tabular data\n",
    "class TabularTransformer(nn.Module):\n",
    "    def __init__(self, num_continuous, num_classes, emb_dim=32, n_heads=4, n_layers=2, hidden_dim=64, dropout=0.1):\n",
    "        super(TabularTransformer, self).__init__()\n",
    "        \n",
    "        # Embedding layer for continuous features\n",
    "        self.embedding = nn.Linear(num_continuous, emb_dim)\n",
    "        \n",
    "        # Transformer encoder layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim, nhead=n_heads, dim_feedforward=hidden_dim, dropout=dropout\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        \n",
    "        # Output classification head\n",
    "        self.fc = nn.Linear(emb_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Embed continuous features\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        # Add positional encoding (optional)\n",
    "        x_emb = x_emb.unsqueeze(1)  # Add a fake sequence dimension\n",
    "        \n",
    "        # Pass through transformer\n",
    "        x_trans = self.transformer(x_emb)\n",
    "        \n",
    "        # Take the mean of all outputs (global average pooling)\n",
    "        x_pooled = x_trans.mean(dim=1)\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.fc(x_pooled)\n",
    "        return out\n",
    "\n",
    "# Prepare Data\n",
    "# Assume X and y are already loaded as NumPy arrays or pandas DataFrames\n",
    "# Replace this with your actual data loading code\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize continuous features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Create PyTorch datasets and data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Initialize the model\n",
    "model = TabularTransformer(\n",
    "    num_continuous=X_train_tensor.shape[1],\n",
    "    num_classes=len(torch.unique(y_train_tensor)),\n",
    "    emb_dim=64,  # Increased embedding dimension\n",
    "    n_heads=8,   # More attention heads\n",
    "    n_layers=4,  # Deeper transformer\n",
    "    hidden_dim=128,  # Larger hidden size\n",
    "    dropout=0.2  # Higher dropout\n",
    ")\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # Reduce LR every 5 epochs\n",
    "model.to(device) \n",
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss/len(train_loader)}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2850\n",
      "           1       1.00      1.00      1.00      2150\n",
      "\n",
      "    accuracy                           1.00      5000\n",
      "   macro avg       1.00      1.00      1.00      5000\n",
      "weighted avg       1.00      1.00      1.00      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(y_batch.cpu().numpy())\n",
    "\n",
    "print(classification_report(all_targets, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/tabular_transformer_model_1000epoch.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularTransformer(\n",
       "  (embedding): Linear(in_features=11, out_features=64, bias=True)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model\n",
    "\n",
    "# Load the model\n",
    "model = TabularTransformer(\n",
    "    num_continuous=X_train_tensor.shape[1],\n",
    "    num_classes=len(torch.unique(y_train_tensor)),\n",
    "    emb_dim=64,  # Increased embedding dimension\n",
    "    n_heads=8,   # More attention heads\n",
    "    n_layers=4,  # Deeper transformer\n",
    "    hidden_dim=128,  # Larger hidden size\n",
    "    dropout=0.2  # Higher dropout\n",
    ")\n",
    "model.load_state_dict(torch.load(\"model/tabular_transformer_model.pth\"), strict=False)\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['embedding.weight', 'embedding.bias', 'transformer.layers.0.self_attn.in_proj_weight', 'transformer.layers.0.self_attn.in_proj_bias', 'transformer.layers.0.self_attn.out_proj.weight', 'transformer.layers.0.self_attn.out_proj.bias', 'transformer.layers.0.linear1.weight', 'transformer.layers.0.linear1.bias', 'transformer.layers.0.linear2.weight', 'transformer.layers.0.linear2.bias', 'transformer.layers.0.norm1.weight', 'transformer.layers.0.norm1.bias', 'transformer.layers.0.norm2.weight', 'transformer.layers.0.norm2.bias', 'transformer.layers.1.self_attn.in_proj_weight', 'transformer.layers.1.self_attn.in_proj_bias', 'transformer.layers.1.self_attn.out_proj.weight', 'transformer.layers.1.self_attn.out_proj.bias', 'transformer.layers.1.linear1.weight', 'transformer.layers.1.linear1.bias', 'transformer.layers.1.linear2.weight', 'transformer.layers.1.linear2.bias', 'transformer.layers.1.norm1.weight', 'transformer.layers.1.norm1.bias', 'transformer.layers.1.norm2.weight', 'transformer.layers.1.norm2.bias', 'transformer.layers.2.self_attn.in_proj_weight', 'transformer.layers.2.self_attn.in_proj_bias', 'transformer.layers.2.self_attn.out_proj.weight', 'transformer.layers.2.self_attn.out_proj.bias', 'transformer.layers.2.linear1.weight', 'transformer.layers.2.linear1.bias', 'transformer.layers.2.linear2.weight', 'transformer.layers.2.linear2.bias', 'transformer.layers.2.norm1.weight', 'transformer.layers.2.norm1.bias', 'transformer.layers.2.norm2.weight', 'transformer.layers.2.norm2.bias', 'transformer.layers.3.self_attn.in_proj_weight', 'transformer.layers.3.self_attn.in_proj_bias', 'transformer.layers.3.self_attn.out_proj.weight', 'transformer.layers.3.self_attn.out_proj.bias', 'transformer.layers.3.linear1.weight', 'transformer.layers.3.linear1.bias', 'transformer.layers.3.linear2.weight', 'transformer.layers.3.linear2.bias', 'transformer.layers.3.norm1.weight', 'transformer.layers.3.norm1.bias', 'transformer.layers.3.norm2.weight', 'transformer.layers.3.norm2.bias', 'fc.weight', 'fc.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(torch.load(\"model/tabular_transformer_model_1000epoch.pth\").keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model with architechture and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularTransformer(\n",
       "  (embedding): Linear(in_features=11, out_features=64, bias=True)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model, \"model/final_tabular_transformer_full_model_1000epoch.pth\")\n",
    "\n",
    "# Load the model\n",
    "model = torch.load(\"model/final_tabular_transformer_full_model_1000epoch.pth\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)  # Should print 'cuda:0' or 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu cpu\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_loader:\n",
    "    print(X_batch.device, y_batch.device)  # Should print 'cuda:0' or 'cpu'\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motor should be Off\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Move the model to CUDA (or CPU if CUDA is unavailable)\n",
    "\n",
    "# Example batch of new data\n",
    "batch_data = [\n",
    "    [0,14.67,53.42,40.80,51.32,32.56,4,1,278.54,4.55,8.44], \n",
    "] \n",
    "\n",
    "# Scale and convert to tensor\n",
    "batch_data_scaled = scaler.transform(batch_data)\n",
    "batch_data_tensor = torch.tensor(batch_data_scaled, dtype=torch.float32)# Ensure tensor is on the same device\n",
    "batch_data_tensor = batch_data_tensor.to(device)\n",
    "# Predict for the batch\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch_data_tensor)  # Now this should work without device mismatch\n",
    "    _, predicted = torch.max(outputs, 1)  # Get the predicted class (0 or 1)\n",
    "\n",
    "    # Convert predictions to motor states (On/Off)\n",
    "    for i, pred in enumerate(predicted.cpu().numpy()):  # Ensure that predictions are moved back to CPU for printing\n",
    "        state = \"On\" if pred == 1 else \"Off\"\n",
    "        print(f\"Motor should be {state}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n",
      "Input tensor is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "print(f\"Input tensor is on device: {batch_data_tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
